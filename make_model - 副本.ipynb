{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd47ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import io\n",
    "import csv\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1169666a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#进行数据清洗的测试，从训练集中读取数据\n",
    "data = pd.read_csv('train_usual.csv',header=None)\n",
    "#加入列名\n",
    "data.columns=[\"label\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7fa50b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>气死 姐姐 了 ， 快二是 阵亡 了 吗 ， 尼玛 ， 一个半 小时 过去 了 也 没 上车</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>妞妞 啊 ， 今天 又 承办 了 一个 发文 登记 文号 是 126 ~ 嘻 ~ 么 么 哒...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>这里 还 值得注意 另 一个 事实 ， 就是 张鞠存 原有 一个 东溪 草堂 为 其 读书处 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>这 在 前 华约 国家 ( 尤其 是 东德 ) 使用 R - 73 的 首次 联合演习 期间...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TinyThief 上 wii 了 ？ ！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1     气死 姐姐 了 ， 快二是 阵亡 了 吗 ， 尼玛 ， 一个半 小时 过去 了 也 没 上车\n",
       "1      2  妞妞 啊 ， 今天 又 承办 了 一个 发文 登记 文号 是 126 ~ 嘻 ~ 么 么 哒...\n",
       "2      6   这里 还 值得注意 另 一个 事实 ， 就是 张鞠存 原有 一个 东溪 草堂 为 其 读书处 。\n",
       "3      6  这 在 前 华约 国家 ( 尤其 是 东德 ) 使用 R - 73 的 首次 联合演习 期间...\n",
       "4      5                              TinyThief 上 wii 了 ？ ！"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9a96de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27766 entries, 0 to 27765\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   27766 non-null  int64 \n",
      " 1   text    27766 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 434.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861e7fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8343\n",
       "6    5749\n",
       "2    5378\n",
       "3    4990\n",
       "5    2086\n",
       "4    1220\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2691abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.020709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.898212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  27766.000000\n",
       "mean       3.020709\n",
       "std        1.898212\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        3.000000\n",
       "75%        5.000000\n",
       "max        6.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e261ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看每一列是否有缺失：\n",
    "data.isna().any(axis=0)\n",
    "# 查看每一行是否有缺失：\n",
    "data.isna().any(axis=1)\n",
    "# 查看所有数据中是否有缺少最快的，没有输出False，反之为True：\n",
    "data.isna().values.any()\n",
    "#data[data.isna().values==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37a3fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27766.000000\n",
       "mean        69.081142\n",
       "std         48.949356\n",
       "min         13.000000\n",
       "25%         35.000000\n",
       "50%         52.000000\n",
       "75%         84.000000\n",
       "max        371.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].map(len).describe()\n",
    "#计算文本的长度，其中mean为均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a322dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8343\n",
       "6    5749\n",
       "2    5378\n",
       "3    4990\n",
       "5    2086\n",
       "4    1220\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['label'].value_counts(normalize=True).plot(kind='bar');\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc9ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5000 non-null   int64 \n",
      " 1   text    5000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('test_usual.csv',header=None)\n",
    "data.columns=[\"label\",\"text\"]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "623d41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   2000 non-null   int64 \n",
      " 1   text    2000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('dev_usual.csv',header=None)\n",
    "data.columns=[\"label\",\"text\"]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16c0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据清洗函数\n",
    "def clean_data(old_path,save_path,save_name):\n",
    "    with open(old_path, 'r', encoding='utf8') as f:\n",
    "        data = defaultdict(list)\n",
    "        texts = f.readlines()\n",
    "        for line in tqdm(texts, desc=old_path):\n",
    "            label,text= line.strip().split(',',1)\n",
    "            emoji = json.load(open('C:/Users/23106/Desktop/weibopy/emoji.json', 'r', encoding='utf8'))\n",
    "            for emoji, emoji_text in emoji.items():\n",
    "                text = text.replace(emoji,emoji_text )\n",
    "            new_text=re.sub('[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+', \"\", text)\n",
    "            data['text'].append(new_text)\n",
    "            \n",
    "            data['label'].append(label)\n",
    "            #将label与text交换位置\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(os.path.join(save_path,save_name), index=False,encoding='utf8', header=False, sep='\\t')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409f5448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:/Users/23106/Desktop/weibopy/dev_usual.csv: 100%|██████████| 2000/2000 [00:01<00:00, 1308.94it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_data('C:/Users/23106/Desktop/weibopy/dev_usual.csv','C:/Users/23106/Desktop/weibopy/new/','valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dcd6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从经过数据清洗后生成的文件中读取数据\n",
    "data = pd.read_csv('C:/Users/23106/Desktop/weibopy/new/train.csv',sep='\\t',header=None)\n",
    "#加入列名\n",
    "data.columns=[\"text\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6327d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这在前华约国家尤其是东德使用的首次联合演习期间被一些北约组织的飞行员所证实</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>上了</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>每天都以紧张的心情工作真的是太累太不放松了想要爆发一下</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>语文军数学军英语军物理军政治军历史军生物军地理军八科联军侵犯我班我班战败被迫签订家长会条约赔...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>我不是一个优秀的演员不能微笑着旁观你们幸福</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>当你变优秀时你想要的都会来找你</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>累了一天会宿舍听下我搞基新歌在看看我段宜恩美图心都被治愈了</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>劳资也能遇到这种人滚你妈逼的狗都不如艹</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>四年又是四年中国球迷有几个四年可以任你挥霍我去年买了个表</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>前几天爸爸带回来的大鱼斤</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>可怕的噩梦不知道我描述的清不在做梦梦里的我也在睡梦中做梦的我梦里还是在做梦起先我第一次醒来以...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>跟一群维族在一起喝酒醉的一塌糊涂</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0                          气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车      1\n",
       "1                           妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟      2\n",
       "2                      这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处      6\n",
       "3               这在前华约国家尤其是东德使用的首次联合演习期间被一些北约组织的飞行员所证实      6\n",
       "4                                                  上了      5\n",
       "5                         每天都以紧张的心情工作真的是太累太不放松了想要爆发一下      1\n",
       "6   语文军数学军英语军物理军政治军历史军生物军地理军八科联军侵犯我班我班战败被迫签订家长会条约赔...      1\n",
       "7                               我不是一个优秀的演员不能微笑着旁观你们幸福      3\n",
       "8                                     当你变优秀时你想要的都会来找你      2\n",
       "9                       累了一天会宿舍听下我搞基新歌在看看我段宜恩美图心都被治愈了      2\n",
       "10                                劳资也能遇到这种人滚你妈逼的狗都不如艹      1\n",
       "11                       四年又是四年中国球迷有几个四年可以任你挥霍我去年买了个表      1\n",
       "12                                       前几天爸爸带回来的大鱼斤      2\n",
       "13  可怕的噩梦不知道我描述的清不在做梦梦里的我也在睡梦中做梦的我梦里还是在做梦起先我第一次醒来以...      4\n",
       "14                                   跟一群维族在一起喝酒醉的一塌糊涂      6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d59114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将label中的数字进行转化，便于查看\n",
    "data.loc[data['label']==1, 'label'] = '愤怒'\n",
    "data.loc[data['label']==2, 'label'] = '积极'\n",
    "data.loc[data['label']==3, 'label'] = '悲伤'\n",
    "data.loc[data['label']==4, 'label'] = '恐惧'\n",
    "data.loc[data['label']==5, 'label'] = '惊奇'\n",
    "data.loc[data['label']==6, 'label'] = '无情绪'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b53747e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟</td>\n",
       "      <td>积极</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处</td>\n",
       "      <td>无情绪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这在前华约国家尤其是东德使用的首次联合演习期间被一些北约组织的飞行员所证实</td>\n",
       "      <td>无情绪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>上了</td>\n",
       "      <td>惊奇</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>每天都以紧张的心情工作真的是太累太不放松了想要爆发一下</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>语文军数学军英语军物理军政治军历史军生物军地理军八科联军侵犯我班我班战败被迫签订家长会条约赔...</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>我不是一个优秀的演员不能微笑着旁观你们幸福</td>\n",
       "      <td>悲伤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>当你变优秀时你想要的都会来找你</td>\n",
       "      <td>积极</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>累了一天会宿舍听下我搞基新歌在看看我段宜恩美图心都被治愈了</td>\n",
       "      <td>积极</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>劳资也能遇到这种人滚你妈逼的狗都不如艹</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>四年又是四年中国球迷有几个四年可以任你挥霍我去年买了个表</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>前几天爸爸带回来的大鱼斤</td>\n",
       "      <td>积极</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>可怕的噩梦不知道我描述的清不在做梦梦里的我也在睡梦中做梦的我梦里还是在做梦起先我第一次醒来以...</td>\n",
       "      <td>恐惧</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text label\n",
       "0                          气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车    愤怒\n",
       "1                           妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟    积极\n",
       "2                      这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处   无情绪\n",
       "3               这在前华约国家尤其是东德使用的首次联合演习期间被一些北约组织的飞行员所证实   无情绪\n",
       "4                                                  上了    惊奇\n",
       "5                         每天都以紧张的心情工作真的是太累太不放松了想要爆发一下    愤怒\n",
       "6   语文军数学军英语军物理军政治军历史军生物军地理军八科联军侵犯我班我班战败被迫签订家长会条约赔...    愤怒\n",
       "7                               我不是一个优秀的演员不能微笑着旁观你们幸福    悲伤\n",
       "8                                     当你变优秀时你想要的都会来找你    积极\n",
       "9                       累了一天会宿舍听下我搞基新歌在看看我段宜恩美图心都被治愈了    积极\n",
       "10                                劳资也能遇到这种人滚你妈逼的狗都不如艹    愤怒\n",
       "11                       四年又是四年中国球迷有几个四年可以任你挥霍我去年买了个表    愤怒\n",
       "12                                       前几天爸爸带回来的大鱼斤    积极\n",
       "13  可怕的噩梦不知道我描述的清不在做梦梦里的我也在睡梦中做梦的我梦里还是在做梦起先我第一次醒来以...    恐惧"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e508eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'label']]\n",
    "data.to_csv('C:/Users/23106/Desktop/weibopy/new/train.csv', index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5ca4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从经过数据清洗后生成的文件中读取数据\n",
    "data = pd.read_csv('C:/Users/23106/Desktop/weibopy/new/test.csv',sep='\\t',header=None)\n",
    "#加入列名\n",
    "data.columns=[\"text\",\"label\"]\n",
    "#将label中的数字进行转化，便于查看\n",
    "data.loc[data['label']==1, 'label'] = '愤怒'\n",
    "data.loc[data['label']==2, 'label'] = '积极'\n",
    "data.loc[data['label']==3, 'label'] = '悲伤'\n",
    "data.loc[data['label']==4, 'label'] = '恐惧'\n",
    "data.loc[data['label']==5, 'label'] = '惊奇'\n",
    "data.loc[data['label']==6, 'label'] = '无情绪'\n",
    "data = data[['text', 'label']]\n",
    "data.to_csv('C:/Users/23106/Desktop/weibopy/new/test.csv', index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c242cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从经过数据清洗后生成的文件中读取数据\n",
    "data = pd.read_csv('C:/Users/23106/Desktop/weibopy/new/valid.csv',sep='\\t',header=None)\n",
    "#加入列名\n",
    "data.columns=[\"text\",\"label\"]\n",
    "#将label中的数字进行转化，便于查看\n",
    "data.loc[data['label']==1, 'label'] = '愤怒'\n",
    "data.loc[data['label']==2, 'label'] = '积极'\n",
    "data.loc[data['label']==3, 'label'] = '悲伤'\n",
    "data.loc[data['label']==4, 'label'] = '恐惧'\n",
    "data.loc[data['label']==5, 'label'] = '惊奇'\n",
    "data.loc[data['label']==6, 'label'] = '无情绪'\n",
    "data = data[['text', 'label']]\n",
    "data.to_csv('C:/Users/23106/Desktop/weibopy/new/valid.csv', index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e016e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "train_data = pd.read_csv('C:/Users/23106/Desktop/weibopy/new/train.csv',sep='\\t',header=None)\n",
    "train_data.columns=[\"label\",\"text\"]\n",
    "test_data = pd.read_csv('C:/Users/23106/Desktop/weibopy/new/test.csv',sep='\\t',header=None)\n",
    "test_data.columns=[\"label\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dabc71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>宿舍要民汉合宿了为毛都大三了还要折腾我</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>早上的我竟然也变成了一个无理取闹的人</td>\n",
       "      <td>悲伤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>多年来周天先生率智多星的律师策划师团队走出巴蜀挺进海西在厦门特区的发祥地安营扎寨</td>\n",
       "      <td>无情绪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>听故事的时候你总喜欢眼巴巴的问后来呢可是当后来自己成为讲故事的人才发现后来故事和话语就在嘴边...</td>\n",
       "      <td>悲伤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label   text\n",
       "0                                               text  label\n",
       "1                                宿舍要民汉合宿了为毛都大三了还要折腾我     愤怒\n",
       "2                                 早上的我竟然也变成了一个无理取闹的人     悲伤\n",
       "3           多年来周天先生率智多星的律师策划师团队走出巴蜀挺进海西在厦门特区的发祥地安营扎寨    无情绪\n",
       "4  听故事的时候你总喜欢眼巴巴的问后来呢可是当后来自己成为讲故事的人才发现后来故事和话语就在嘴边...     悲伤"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b954c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟</td>\n",
       "      <td>积极</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处</td>\n",
       "      <td>无情绪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>这在前华约国家尤其是东德使用的首次联合演习期间被一些北约组织的飞行员所证实</td>\n",
       "      <td>无情绪</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   label   text\n",
       "0                                   text  label\n",
       "1             气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车     愤怒\n",
       "2              妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟     积极\n",
       "3         这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处    无情绪\n",
       "4  这在前华约国家尤其是东德使用的首次联合演习期间被一些北约组织的飞行员所证实    无情绪"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9dbe739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5000 non-null   object\n",
      " 1   text    5001 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#查看测试集信息\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99126e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建情感分析模型\n",
    "import paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1acb6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddlehub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "038cc40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \n",
      "PaddlePaddle works well on 1 GPU.\n",
      "PaddlePaddle works well on 1 GPUs.\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"
     ]
    }
   ],
   "source": [
    "#检测环境是否正常\n",
    "paddle.utils.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ea49a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['愤怒', '积极', '悲伤', '无情绪', '恐惧', '惊奇']\n"
     ]
    }
   ],
   "source": [
    "label_list=list(data.label.unique())\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d150a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '愤怒', 1: '积极', 2: '悲伤', 3: '无情绪', 4: '恐惧', 5: '惊奇'}\n"
     ]
    }
   ],
   "source": [
    "label_map = { \n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b096dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-05-10 15:56:12,373] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\ernie_tiny.pdparams\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 此处选择ernie_tiny预训练模型并设置微调任务为6分类任务\n",
    "model = hub.Module(name=\"ernie_tiny\", task='seq-cls', num_classes=6, label_map=label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c25323d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlehub.datasets.base_nlp_dataset import InputExample, TextClassificationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95d05ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a745b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['愤怒', '积极', '悲伤', '无情绪', '恐惧', '惊奇']\n"
     ]
    }
   ],
   "source": [
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a87a6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR=\"C:/Users/23106/Desktop/weibopy/new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eb84479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-05-10 15:56:14,271] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:14,272] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\spm_cased_simp_sampled.model\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:14,273] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\dict.wordseg.pickle\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:22,779] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:22,780] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\spm_cased_simp_sampled.model\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:22,780] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\dict.wordseg.pickle\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:26,706] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:26,707] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\spm_cased_simp_sampled.model\u001b[0m\n",
      "\u001b[32m[2022-05-10 15:56:26,709] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\dict.wordseg.pickle\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=气死姐姐了快二是阵亡了吗尼玛一个半小时过去了也没上车\tlabel=愤怒\n",
      "text=妞妞啊今天又承办了一个发文登记文号是嘻么么哒晚安哟\tlabel=积极\n",
      "text=这里还值得注意另一个事实就是张鞠存原有一个东溪草堂为其读书处\tlabel=无情绪\n",
      "text=宿舍要民汉合宿了为毛都大三了还要折腾我\tlabel=愤怒\n",
      "text=早上的我竟然也变成了一个无理取闹的人\tlabel=悲伤\n",
      "text=多年来周天先生率智多星的律师策划师团队走出巴蜀挺进海西在厦门特区的发祥地安营扎寨\tlabel=无情绪\n",
      "text=所以注定我这辈子是做不了商人妈蛋\tlabel=愤怒\n",
      "text=无论是心情多么低沉的夜晚天光大亮后都是崭新的开始\tlabel=积极\n",
      "text=帽子怎么就变绿色幸好只是试一下\tlabel=悲伤\n"
     ]
    }
   ],
   "source": [
    "class TEXTALS(TextClassificationDataset):\n",
    "    def __init__(self, tokenizer, mode='train', max_seq_len=128):\n",
    "        if mode == 'train':\n",
    "            data_file = 'train.csv'  # 训练集\n",
    "        elif mode == 'test':\n",
    "            data_file = 'test.csv'   # 测试集\n",
    "        else:\n",
    "            data_file = 'valid.csv'  # 验证集\n",
    "        \n",
    "        super(TEXTALS, self).__init__(\n",
    "            base_path=DIR,\n",
    "            data_file=data_file,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=max_seq_len,\n",
    "            mode=mode,\n",
    "            is_file_with_header=True,\n",
    "            label_list=label_list\n",
    "            )\n",
    "\n",
    "    # 解析文本文件里的样本\n",
    "    def _read_file(self, input_file, is_file_with_header: bool = False):\n",
    "        if not os.path.exists(input_file):\n",
    "            raise RuntimeError(\"The file {} is not found.\".format(input_file))\n",
    "        else:\n",
    "            with io.open(input_file, \"r\", encoding=\"UTF-8\") as f:\n",
    "                reader = csv.reader(f, delimiter=\"\\t\")\n",
    "                examples = []\n",
    "                seq_id = 0\n",
    "                header = next(reader) if is_file_with_header else None\n",
    "                for line in reader:\n",
    "                    try:\n",
    "                        example = InputExample(guid=seq_id, text_a=line[0], label=line[1])\n",
    "                        seq_id += 1\n",
    "                        examples.append(example)\n",
    "                    except:\n",
    "                        continue\n",
    "                return examples\n",
    "                \n",
    "train_dataset = TEXTALS(model.get_tokenizer(), mode='train', max_seq_len=128)\n",
    "test_dataset = TEXTALS(model.get_tokenizer(), mode='test', max_seq_len=128)\n",
    "valid_dataset = TEXTALS(model.get_tokenizer(), mode='valid', max_seq_len=128)\n",
    "\n",
    "# 查看训练集前3条\n",
    "for e in train_dataset.examples[:3]:\n",
    "    print(e)\n",
    "# 查看验证集前3条\n",
    "for e in test_dataset.examples[:3]:\n",
    "    print(e)\n",
    "# 查看测试集前3条\n",
    "for e in valid_dataset.examples[:3]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63940efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2022-05-10 15:56:30,109] [ WARNING]\u001b[0m - PaddleHub model checkpoint not found, start from scratch...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#选择优化策略和运行配置\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=4e-5, parameters=model.parameters())\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='./ckpt', use_gpu=True, use_vdl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "806b6a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0\n"
     ]
    }
   ],
   "source": [
    "print(paddle.device.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a64f1374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 15:56:36,213] [   TRAIN]\u001b[0m - Epoch=1/6, Step=10/868 loss=1.6585 acc=0.3531 lr=0.000040 step/sec=1.65 | ETA 00:52:44\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:56:42,211] [   TRAIN]\u001b[0m - Epoch=1/6, Step=20/868 loss=1.3667 acc=0.5188 lr=0.000040 step/sec=1.67 | ETA 00:52:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:56:48,232] [   TRAIN]\u001b[0m - Epoch=1/6, Step=30/868 loss=1.1766 acc=0.6219 lr=0.000040 step/sec=1.66 | ETA 00:52:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:56:54,259] [   TRAIN]\u001b[0m - Epoch=1/6, Step=40/868 loss=1.1105 acc=0.6219 lr=0.000040 step/sec=1.66 | ETA 00:52:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:00,303] [   TRAIN]\u001b[0m - Epoch=1/6, Step=50/868 loss=0.8493 acc=0.7188 lr=0.000040 step/sec=1.65 | ETA 00:52:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:06,330] [   TRAIN]\u001b[0m - Epoch=1/6, Step=60/868 loss=0.8801 acc=0.6750 lr=0.000040 step/sec=1.66 | ETA 00:52:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:12,336] [   TRAIN]\u001b[0m - Epoch=1/6, Step=70/868 loss=0.8899 acc=0.6875 lr=0.000040 step/sec=1.67 | ETA 00:52:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:18,310] [   TRAIN]\u001b[0m - Epoch=1/6, Step=80/868 loss=0.9116 acc=0.6719 lr=0.000040 step/sec=1.67 | ETA 00:52:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:24,342] [   TRAIN]\u001b[0m - Epoch=1/6, Step=90/868 loss=0.8003 acc=0.7125 lr=0.000040 step/sec=1.66 | ETA 00:52:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:30,446] [   TRAIN]\u001b[0m - Epoch=1/6, Step=100/868 loss=0.7793 acc=0.7125 lr=0.000040 step/sec=1.64 | ETA 00:52:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:36,492] [   TRAIN]\u001b[0m - Epoch=1/6, Step=110/868 loss=0.8617 acc=0.6969 lr=0.000040 step/sec=1.65 | ETA 00:52:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:42,639] [   TRAIN]\u001b[0m - Epoch=1/6, Step=120/868 loss=0.8793 acc=0.6906 lr=0.000040 step/sec=1.63 | ETA 00:52:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:48,766] [   TRAIN]\u001b[0m - Epoch=1/6, Step=130/868 loss=0.7746 acc=0.6937 lr=0.000040 step/sec=1.63 | ETA 00:52:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:57:54,818] [   TRAIN]\u001b[0m - Epoch=1/6, Step=140/868 loss=0.7091 acc=0.7406 lr=0.000040 step/sec=1.65 | ETA 00:52:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:01,019] [   TRAIN]\u001b[0m - Epoch=1/6, Step=150/868 loss=0.6962 acc=0.7406 lr=0.000040 step/sec=1.61 | ETA 00:52:35\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:07,219] [   TRAIN]\u001b[0m - Epoch=1/6, Step=160/868 loss=0.6745 acc=0.7625 lr=0.000040 step/sec=1.61 | ETA 00:52:40\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:13,398] [   TRAIN]\u001b[0m - Epoch=1/6, Step=170/868 loss=0.7735 acc=0.7312 lr=0.000040 step/sec=1.62 | ETA 00:52:43\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:19,589] [   TRAIN]\u001b[0m - Epoch=1/6, Step=180/868 loss=0.8381 acc=0.7031 lr=0.000040 step/sec=1.62 | ETA 00:52:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:25,764] [   TRAIN]\u001b[0m - Epoch=1/6, Step=190/868 loss=0.7575 acc=0.7125 lr=0.000040 step/sec=1.62 | ETA 00:52:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:31,855] [   TRAIN]\u001b[0m - Epoch=1/6, Step=200/868 loss=0.6805 acc=0.7406 lr=0.000040 step/sec=1.64 | ETA 00:52:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:37,956] [   TRAIN]\u001b[0m - Epoch=1/6, Step=210/868 loss=0.7106 acc=0.7719 lr=0.000040 step/sec=1.64 | ETA 00:52:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:44,036] [   TRAIN]\u001b[0m - Epoch=1/6, Step=220/868 loss=0.7219 acc=0.7281 lr=0.000040 step/sec=1.64 | ETA 00:52:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:50,149] [   TRAIN]\u001b[0m - Epoch=1/6, Step=230/868 loss=0.6902 acc=0.7562 lr=0.000040 step/sec=1.64 | ETA 00:52:50\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:58:56,258] [   TRAIN]\u001b[0m - Epoch=1/6, Step=240/868 loss=0.6671 acc=0.7688 lr=0.000040 step/sec=1.64 | ETA 00:52:50\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:02,361] [   TRAIN]\u001b[0m - Epoch=1/6, Step=250/868 loss=0.7023 acc=0.7406 lr=0.000040 step/sec=1.64 | ETA 00:52:51\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:08,463] [   TRAIN]\u001b[0m - Epoch=1/6, Step=260/868 loss=0.6961 acc=0.7406 lr=0.000040 step/sec=1.64 | ETA 00:52:51\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:14,568] [   TRAIN]\u001b[0m - Epoch=1/6, Step=270/868 loss=0.7105 acc=0.7469 lr=0.000040 step/sec=1.64 | ETA 00:52:51\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:20,691] [   TRAIN]\u001b[0m - Epoch=1/6, Step=280/868 loss=0.6475 acc=0.7750 lr=0.000040 step/sec=1.63 | ETA 00:52:52\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:26,818] [   TRAIN]\u001b[0m - Epoch=1/6, Step=290/868 loss=0.6554 acc=0.7688 lr=0.000040 step/sec=1.63 | ETA 00:52:52\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:32,957] [   TRAIN]\u001b[0m - Epoch=1/6, Step=300/868 loss=0.7089 acc=0.7344 lr=0.000040 step/sec=1.63 | ETA 00:52:53\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:39,113] [   TRAIN]\u001b[0m - Epoch=1/6, Step=310/868 loss=0.7338 acc=0.7344 lr=0.000040 step/sec=1.62 | ETA 00:52:54\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:45,461] [   TRAIN]\u001b[0m - Epoch=1/6, Step=320/868 loss=0.7686 acc=0.7094 lr=0.000040 step/sec=1.58 | ETA 00:52:58\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:51,812] [   TRAIN]\u001b[0m - Epoch=1/6, Step=330/868 loss=0.7177 acc=0.7250 lr=0.000040 step/sec=1.57 | ETA 00:53:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 15:59:58,053] [   TRAIN]\u001b[0m - Epoch=1/6, Step=340/868 loss=0.6700 acc=0.7750 lr=0.000040 step/sec=1.60 | ETA 00:53:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:04,463] [   TRAIN]\u001b[0m - Epoch=1/6, Step=350/868 loss=0.6923 acc=0.7531 lr=0.000040 step/sec=1.56 | ETA 00:53:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:10,717] [   TRAIN]\u001b[0m - Epoch=1/6, Step=360/868 loss=0.6649 acc=0.7562 lr=0.000040 step/sec=1.60 | ETA 00:53:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:16,971] [   TRAIN]\u001b[0m - Epoch=1/6, Step=370/868 loss=0.7582 acc=0.7375 lr=0.000040 step/sec=1.60 | ETA 00:53:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:23,104] [   TRAIN]\u001b[0m - Epoch=1/6, Step=380/868 loss=0.6515 acc=0.7750 lr=0.000040 step/sec=1.63 | ETA 00:53:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:29,186] [   TRAIN]\u001b[0m - Epoch=1/6, Step=390/868 loss=0.6739 acc=0.7594 lr=0.000040 step/sec=1.64 | ETA 00:53:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:35,327] [   TRAIN]\u001b[0m - Epoch=1/6, Step=400/868 loss=0.6611 acc=0.7469 lr=0.000040 step/sec=1.63 | ETA 00:53:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:41,444] [   TRAIN]\u001b[0m - Epoch=1/6, Step=410/868 loss=0.7804 acc=0.7219 lr=0.000040 step/sec=1.63 | ETA 00:53:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:47,636] [   TRAIN]\u001b[0m - Epoch=1/6, Step=420/868 loss=0.6703 acc=0.7281 lr=0.000040 step/sec=1.61 | ETA 00:53:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:00:53,955] [   TRAIN]\u001b[0m - Epoch=1/6, Step=430/868 loss=0.7223 acc=0.7125 lr=0.000040 step/sec=1.58 | ETA 00:53:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:00,415] [   TRAIN]\u001b[0m - Epoch=1/6, Step=440/868 loss=0.5804 acc=0.8094 lr=0.000040 step/sec=1.55 | ETA 00:53:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:06,542] [   TRAIN]\u001b[0m - Epoch=1/6, Step=450/868 loss=0.5842 acc=0.7875 lr=0.000040 step/sec=1.63 | ETA 00:53:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:12,690] [   TRAIN]\u001b[0m - Epoch=1/6, Step=460/868 loss=0.6099 acc=0.8094 lr=0.000040 step/sec=1.63 | ETA 00:53:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:18,809] [   TRAIN]\u001b[0m - Epoch=1/6, Step=470/868 loss=0.7948 acc=0.7125 lr=0.000040 step/sec=1.63 | ETA 00:53:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:25,009] [   TRAIN]\u001b[0m - Epoch=1/6, Step=480/868 loss=0.7124 acc=0.7562 lr=0.000040 step/sec=1.61 | ETA 00:53:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:31,357] [   TRAIN]\u001b[0m - Epoch=1/6, Step=490/868 loss=0.6486 acc=0.7250 lr=0.000040 step/sec=1.58 | ETA 00:53:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:37,756] [   TRAIN]\u001b[0m - Epoch=1/6, Step=500/868 loss=0.7093 acc=0.7500 lr=0.000040 step/sec=1.56 | ETA 00:53:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:43,919] [   TRAIN]\u001b[0m - Epoch=1/6, Step=510/868 loss=0.6461 acc=0.7750 lr=0.000040 step/sec=1.62 | ETA 00:53:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:50,258] [   TRAIN]\u001b[0m - Epoch=1/6, Step=520/868 loss=0.7478 acc=0.7281 lr=0.000040 step/sec=1.58 | ETA 00:53:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:01:56,464] [   TRAIN]\u001b[0m - Epoch=1/6, Step=530/868 loss=0.7463 acc=0.7344 lr=0.000040 step/sec=1.61 | ETA 00:53:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:02,971] [   TRAIN]\u001b[0m - Epoch=1/6, Step=540/868 loss=0.6677 acc=0.7719 lr=0.000040 step/sec=1.54 | ETA 00:53:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:09,858] [   TRAIN]\u001b[0m - Epoch=1/6, Step=550/868 loss=0.7442 acc=0.7063 lr=0.000040 step/sec=1.45 | ETA 00:53:36\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:16,404] [   TRAIN]\u001b[0m - Epoch=1/6, Step=560/868 loss=0.7899 acc=0.7469 lr=0.000040 step/sec=1.53 | ETA 00:53:40\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:22,672] [   TRAIN]\u001b[0m - Epoch=1/6, Step=570/868 loss=0.6834 acc=0.7594 lr=0.000040 step/sec=1.60 | ETA 00:53:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:28,989] [   TRAIN]\u001b[0m - Epoch=1/6, Step=580/868 loss=0.7089 acc=0.7562 lr=0.000040 step/sec=1.58 | ETA 00:53:42\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:35,146] [   TRAIN]\u001b[0m - Epoch=1/6, Step=590/868 loss=0.7644 acc=0.7344 lr=0.000040 step/sec=1.62 | ETA 00:53:41\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:02:41,309] [   TRAIN]\u001b[0m - Epoch=1/6, Step=600/868 loss=0.7366 acc=0.7375 lr=0.000040 step/sec=1.62 | ETA 00:53:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:47,442] [   TRAIN]\u001b[0m - Epoch=1/6, Step=610/868 loss=0.5847 acc=0.7937 lr=0.000040 step/sec=1.63 | ETA 00:53:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:53,610] [   TRAIN]\u001b[0m - Epoch=1/6, Step=620/868 loss=0.7235 acc=0.7312 lr=0.000040 step/sec=1.62 | ETA 00:53:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:02:59,863] [   TRAIN]\u001b[0m - Epoch=1/6, Step=630/868 loss=0.7007 acc=0.7344 lr=0.000040 step/sec=1.60 | ETA 00:53:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:06,093] [   TRAIN]\u001b[0m - Epoch=1/6, Step=640/868 loss=0.6611 acc=0.7625 lr=0.000040 step/sec=1.61 | ETA 00:53:42\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:12,249] [   TRAIN]\u001b[0m - Epoch=1/6, Step=650/868 loss=0.7017 acc=0.7250 lr=0.000040 step/sec=1.62 | ETA 00:53:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:18,554] [   TRAIN]\u001b[0m - Epoch=1/6, Step=660/868 loss=0.6738 acc=0.7688 lr=0.000040 step/sec=1.59 | ETA 00:53:42\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:25,063] [   TRAIN]\u001b[0m - Epoch=1/6, Step=670/868 loss=0.7263 acc=0.7219 lr=0.000040 step/sec=1.54 | ETA 00:53:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:31,458] [   TRAIN]\u001b[0m - Epoch=1/6, Step=680/868 loss=0.6716 acc=0.7562 lr=0.000040 step/sec=1.56 | ETA 00:53:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:37,821] [   TRAIN]\u001b[0m - Epoch=1/6, Step=690/868 loss=0.6268 acc=0.7500 lr=0.000040 step/sec=1.57 | ETA 00:53:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:44,161] [   TRAIN]\u001b[0m - Epoch=1/6, Step=700/868 loss=0.6731 acc=0.7656 lr=0.000040 step/sec=1.58 | ETA 00:53:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:50,342] [   TRAIN]\u001b[0m - Epoch=1/6, Step=710/868 loss=0.6686 acc=0.7562 lr=0.000040 step/sec=1.62 | ETA 00:53:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:03:56,540] [   TRAIN]\u001b[0m - Epoch=1/6, Step=720/868 loss=0.5865 acc=0.7875 lr=0.000040 step/sec=1.61 | ETA 00:53:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:02,661] [   TRAIN]\u001b[0m - Epoch=1/6, Step=730/868 loss=0.7162 acc=0.7656 lr=0.000040 step/sec=1.63 | ETA 00:53:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:08,812] [   TRAIN]\u001b[0m - Epoch=1/6, Step=740/868 loss=0.7141 acc=0.7438 lr=0.000040 step/sec=1.63 | ETA 00:53:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:14,964] [   TRAIN]\u001b[0m - Epoch=1/6, Step=750/868 loss=0.7394 acc=0.7281 lr=0.000040 step/sec=1.63 | ETA 00:53:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:21,132] [   TRAIN]\u001b[0m - Epoch=1/6, Step=760/868 loss=0.6500 acc=0.7500 lr=0.000040 step/sec=1.62 | ETA 00:53:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:27,299] [   TRAIN]\u001b[0m - Epoch=1/6, Step=770/868 loss=0.7157 acc=0.7188 lr=0.000040 step/sec=1.62 | ETA 00:53:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:33,431] [   TRAIN]\u001b[0m - Epoch=1/6, Step=780/868 loss=0.7815 acc=0.6906 lr=0.000040 step/sec=1.63 | ETA 00:53:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:39,558] [   TRAIN]\u001b[0m - Epoch=1/6, Step=790/868 loss=0.6843 acc=0.7500 lr=0.000040 step/sec=1.63 | ETA 00:53:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:45,683] [   TRAIN]\u001b[0m - Epoch=1/6, Step=800/868 loss=0.6007 acc=0.7844 lr=0.000040 step/sec=1.63 | ETA 00:53:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:51,832] [   TRAIN]\u001b[0m - Epoch=1/6, Step=810/868 loss=0.6194 acc=0.7594 lr=0.000040 step/sec=1.63 | ETA 00:53:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:04:58,034] [   TRAIN]\u001b[0m - Epoch=1/6, Step=820/868 loss=0.7178 acc=0.7438 lr=0.000040 step/sec=1.61 | ETA 00:53:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:05:04,171] [   TRAIN]\u001b[0m - Epoch=1/6, Step=830/868 loss=0.6624 acc=0.7688 lr=0.000040 step/sec=1.63 | ETA 00:53:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:05:10,246] [   TRAIN]\u001b[0m - Epoch=1/6, Step=840/868 loss=0.6044 acc=0.7656 lr=0.000040 step/sec=1.65 | ETA 00:53:44\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:05:16,245] [   TRAIN]\u001b[0m - Epoch=1/6, Step=850/868 loss=0.6248 acc=0.7531 lr=0.000040 step/sec=1.67 | ETA 00:53:43\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:05:22,270] [   TRAIN]\u001b[0m - Epoch=1/6, Step=860/868 loss=0.6354 acc=0.7531 lr=0.000040 step/sec=1.66 | ETA 00:53:42\u001b[0m\n",
      "\u001b[34m[2022-05-10 16:05:40,585] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7610\u001b[0mm\n",
      "\u001b[34m[2022-05-10 16:05:42,298] [    EVAL]\u001b[0m - Saving best model to ./ckpt\\best_model [best acc=0.7610]\u001b[0m\n",
      "\u001b[32m[2022-05-10 16:05:42,299] [    INFO]\u001b[0m - Saving model checkpoint to ./ckpt\\epoch_1\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:05:50,225] [   TRAIN]\u001b[0m - Epoch=2/6, Step=10/868 loss=0.4413 acc=0.8406 lr=0.000040 step/sec=0.64 | ETA 00:55:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:05:56,413] [   TRAIN]\u001b[0m - Epoch=2/6, Step=20/868 loss=0.4766 acc=0.8375 lr=0.000040 step/sec=1.62 | ETA 00:55:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:02,560] [   TRAIN]\u001b[0m - Epoch=2/6, Step=30/868 loss=0.5384 acc=0.7812 lr=0.000040 step/sec=1.63 | ETA 00:55:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:08,727] [   TRAIN]\u001b[0m - Epoch=2/6, Step=40/868 loss=0.5164 acc=0.8031 lr=0.000040 step/sec=1.62 | ETA 00:55:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:14,919] [   TRAIN]\u001b[0m - Epoch=2/6, Step=50/868 loss=0.4142 acc=0.8469 lr=0.000040 step/sec=1.62 | ETA 00:55:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:21,067] [   TRAIN]\u001b[0m - Epoch=2/6, Step=60/868 loss=0.4815 acc=0.8156 lr=0.000040 step/sec=1.63 | ETA 00:55:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:27,238] [   TRAIN]\u001b[0m - Epoch=2/6, Step=70/868 loss=0.4212 acc=0.8406 lr=0.000040 step/sec=1.62 | ETA 00:55:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:33,474] [   TRAIN]\u001b[0m - Epoch=2/6, Step=80/868 loss=0.4699 acc=0.8313 lr=0.000040 step/sec=1.60 | ETA 00:55:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:39,647] [   TRAIN]\u001b[0m - Epoch=2/6, Step=90/868 loss=0.5940 acc=0.7688 lr=0.000040 step/sec=1.62 | ETA 00:55:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:45,769] [   TRAIN]\u001b[0m - Epoch=2/6, Step=100/868 loss=0.5128 acc=0.7969 lr=0.000040 step/sec=1.63 | ETA 00:55:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:51,981] [   TRAIN]\u001b[0m - Epoch=2/6, Step=110/868 loss=0.5672 acc=0.7719 lr=0.000040 step/sec=1.61 | ETA 00:55:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:06:57,999] [   TRAIN]\u001b[0m - Epoch=2/6, Step=120/868 loss=0.5299 acc=0.8250 lr=0.000040 step/sec=1.66 | ETA 00:55:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:04,109] [   TRAIN]\u001b[0m - Epoch=2/6, Step=130/868 loss=0.4607 acc=0.8313 lr=0.000040 step/sec=1.64 | ETA 00:55:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:10,272] [   TRAIN]\u001b[0m - Epoch=2/6, Step=140/868 loss=0.5384 acc=0.8094 lr=0.000040 step/sec=1.62 | ETA 00:55:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:16,585] [   TRAIN]\u001b[0m - Epoch=2/6, Step=150/868 loss=0.4101 acc=0.8438 lr=0.000040 step/sec=1.58 | ETA 00:55:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:22,838] [   TRAIN]\u001b[0m - Epoch=2/6, Step=160/868 loss=0.5248 acc=0.8063 lr=0.000040 step/sec=1.60 | ETA 00:55:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:29,102] [   TRAIN]\u001b[0m - Epoch=2/6, Step=170/868 loss=0.4976 acc=0.8156 lr=0.000040 step/sec=1.60 | ETA 00:55:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:35,510] [   TRAIN]\u001b[0m - Epoch=2/6, Step=180/868 loss=0.4555 acc=0.8313 lr=0.000040 step/sec=1.56 | ETA 00:55:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:41,680] [   TRAIN]\u001b[0m - Epoch=2/6, Step=190/868 loss=0.5817 acc=0.8000 lr=0.000040 step/sec=1.62 | ETA 00:55:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:47,855] [   TRAIN]\u001b[0m - Epoch=2/6, Step=200/868 loss=0.5355 acc=0.8125 lr=0.000040 step/sec=1.62 | ETA 00:55:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:07:54,022] [   TRAIN]\u001b[0m - Epoch=2/6, Step=210/868 loss=0.4669 acc=0.8125 lr=0.000040 step/sec=1.62 | ETA 00:55:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:00,193] [   TRAIN]\u001b[0m - Epoch=2/6, Step=220/868 loss=0.6034 acc=0.7875 lr=0.000040 step/sec=1.62 | ETA 00:55:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:06,353] [   TRAIN]\u001b[0m - Epoch=2/6, Step=230/868 loss=0.5382 acc=0.7875 lr=0.000040 step/sec=1.62 | ETA 00:55:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:12,527] [   TRAIN]\u001b[0m - Epoch=2/6, Step=240/868 loss=0.4287 acc=0.8281 lr=0.000040 step/sec=1.62 | ETA 00:55:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:18,708] [   TRAIN]\u001b[0m - Epoch=2/6, Step=250/868 loss=0.5050 acc=0.8281 lr=0.000040 step/sec=1.62 | ETA 00:55:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:24,868] [   TRAIN]\u001b[0m - Epoch=2/6, Step=260/868 loss=0.4508 acc=0.8406 lr=0.000040 step/sec=1.62 | ETA 00:54:59\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:31,060] [   TRAIN]\u001b[0m - Epoch=2/6, Step=270/868 loss=0.4746 acc=0.8156 lr=0.000040 step/sec=1.61 | ETA 00:54:59\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:37,219] [   TRAIN]\u001b[0m - Epoch=2/6, Step=280/868 loss=0.5038 acc=0.8125 lr=0.000040 step/sec=1.62 | ETA 00:54:58\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:43,396] [   TRAIN]\u001b[0m - Epoch=2/6, Step=290/868 loss=0.4786 acc=0.8250 lr=0.000040 step/sec=1.62 | ETA 00:54:57\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:08:49,596] [   TRAIN]\u001b[0m - Epoch=2/6, Step=300/868 loss=0.4462 acc=0.8375 lr=0.000040 step/sec=1.61 | ETA 00:54:57\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:08:55,760] [   TRAIN]\u001b[0m - Epoch=2/6, Step=310/868 loss=0.5036 acc=0.8219 lr=0.000040 step/sec=1.62 | ETA 00:54:56\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:02,025] [   TRAIN]\u001b[0m - Epoch=2/6, Step=320/868 loss=0.4717 acc=0.8281 lr=0.000040 step/sec=1.60 | ETA 00:54:56\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:08,204] [   TRAIN]\u001b[0m - Epoch=2/6, Step=330/868 loss=0.4700 acc=0.8344 lr=0.000040 step/sec=1.62 | ETA 00:54:55\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:14,378] [   TRAIN]\u001b[0m - Epoch=2/6, Step=340/868 loss=0.5841 acc=0.7844 lr=0.000040 step/sec=1.62 | ETA 00:54:54\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:20,567] [   TRAIN]\u001b[0m - Epoch=2/6, Step=350/868 loss=0.5489 acc=0.7906 lr=0.000040 step/sec=1.62 | ETA 00:54:54\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:26,881] [   TRAIN]\u001b[0m - Epoch=2/6, Step=360/868 loss=0.3856 acc=0.8781 lr=0.000040 step/sec=1.58 | ETA 00:54:54\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:33,133] [   TRAIN]\u001b[0m - Epoch=2/6, Step=370/868 loss=0.5291 acc=0.7969 lr=0.000040 step/sec=1.60 | ETA 00:54:53\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:39,285] [   TRAIN]\u001b[0m - Epoch=2/6, Step=380/868 loss=0.5058 acc=0.8031 lr=0.000040 step/sec=1.63 | ETA 00:54:53\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:45,433] [   TRAIN]\u001b[0m - Epoch=2/6, Step=390/868 loss=0.4602 acc=0.8281 lr=0.000040 step/sec=1.63 | ETA 00:54:52\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:51,590] [   TRAIN]\u001b[0m - Epoch=2/6, Step=400/868 loss=0.5173 acc=0.8219 lr=0.000040 step/sec=1.62 | ETA 00:54:51\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:09:57,736] [   TRAIN]\u001b[0m - Epoch=2/6, Step=410/868 loss=0.5034 acc=0.8219 lr=0.000040 step/sec=1.63 | ETA 00:54:51\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:03,886] [   TRAIN]\u001b[0m - Epoch=2/6, Step=420/868 loss=0.4241 acc=0.8781 lr=0.000040 step/sec=1.63 | ETA 00:54:50\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:10,031] [   TRAIN]\u001b[0m - Epoch=2/6, Step=430/868 loss=0.6000 acc=0.7844 lr=0.000040 step/sec=1.63 | ETA 00:54:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:16,183] [   TRAIN]\u001b[0m - Epoch=2/6, Step=440/868 loss=0.5526 acc=0.7937 lr=0.000040 step/sec=1.63 | ETA 00:54:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:22,333] [   TRAIN]\u001b[0m - Epoch=2/6, Step=450/868 loss=0.5029 acc=0.8187 lr=0.000040 step/sec=1.63 | ETA 00:54:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:28,482] [   TRAIN]\u001b[0m - Epoch=2/6, Step=460/868 loss=0.5730 acc=0.7969 lr=0.000040 step/sec=1.63 | ETA 00:54:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:34,630] [   TRAIN]\u001b[0m - Epoch=2/6, Step=470/868 loss=0.5554 acc=0.7906 lr=0.000040 step/sec=1.63 | ETA 00:54:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:40,773] [   TRAIN]\u001b[0m - Epoch=2/6, Step=480/868 loss=0.4635 acc=0.8438 lr=0.000040 step/sec=1.63 | ETA 00:54:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:46,921] [   TRAIN]\u001b[0m - Epoch=2/6, Step=490/868 loss=0.4705 acc=0.8344 lr=0.000040 step/sec=1.63 | ETA 00:54:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:53,054] [   TRAIN]\u001b[0m - Epoch=2/6, Step=500/868 loss=0.5956 acc=0.7969 lr=0.000040 step/sec=1.63 | ETA 00:54:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:10:59,185] [   TRAIN]\u001b[0m - Epoch=2/6, Step=510/868 loss=0.5637 acc=0.8156 lr=0.000040 step/sec=1.63 | ETA 00:54:44\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:05,319] [   TRAIN]\u001b[0m - Epoch=2/6, Step=520/868 loss=0.5041 acc=0.8031 lr=0.000040 step/sec=1.63 | ETA 00:54:43\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:11,446] [   TRAIN]\u001b[0m - Epoch=2/6, Step=530/868 loss=0.4061 acc=0.8438 lr=0.000040 step/sec=1.63 | ETA 00:54:43\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:17,588] [   TRAIN]\u001b[0m - Epoch=2/6, Step=540/868 loss=0.3888 acc=0.8781 lr=0.000040 step/sec=1.63 | ETA 00:54:42\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:23,721] [   TRAIN]\u001b[0m - Epoch=2/6, Step=550/868 loss=0.4726 acc=0.8313 lr=0.000040 step/sec=1.63 | ETA 00:54:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:29,853] [   TRAIN]\u001b[0m - Epoch=2/6, Step=560/868 loss=0.5227 acc=0.8156 lr=0.000040 step/sec=1.63 | ETA 00:54:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:35,987] [   TRAIN]\u001b[0m - Epoch=2/6, Step=570/868 loss=0.5234 acc=0.8000 lr=0.000040 step/sec=1.63 | ETA 00:54:40\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:42,122] [   TRAIN]\u001b[0m - Epoch=2/6, Step=580/868 loss=0.5183 acc=0.7937 lr=0.000040 step/sec=1.63 | ETA 00:54:40\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:48,252] [   TRAIN]\u001b[0m - Epoch=2/6, Step=590/868 loss=0.5223 acc=0.8094 lr=0.000040 step/sec=1.63 | ETA 00:54:39\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:11:54,385] [   TRAIN]\u001b[0m - Epoch=2/6, Step=600/868 loss=0.5631 acc=0.8125 lr=0.000040 step/sec=1.63 | ETA 00:54:38\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:00,519] [   TRAIN]\u001b[0m - Epoch=2/6, Step=610/868 loss=0.5002 acc=0.8156 lr=0.000040 step/sec=1.63 | ETA 00:54:38\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:06,653] [   TRAIN]\u001b[0m - Epoch=2/6, Step=620/868 loss=0.4729 acc=0.8406 lr=0.000040 step/sec=1.63 | ETA 00:54:37\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:12,786] [   TRAIN]\u001b[0m - Epoch=2/6, Step=630/868 loss=0.4651 acc=0.8281 lr=0.000040 step/sec=1.63 | ETA 00:54:37\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:18,920] [   TRAIN]\u001b[0m - Epoch=2/6, Step=640/868 loss=0.5212 acc=0.8187 lr=0.000040 step/sec=1.63 | ETA 00:54:36\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:25,055] [   TRAIN]\u001b[0m - Epoch=2/6, Step=650/868 loss=0.4949 acc=0.8281 lr=0.000040 step/sec=1.63 | ETA 00:54:36\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:31,185] [   TRAIN]\u001b[0m - Epoch=2/6, Step=660/868 loss=0.4880 acc=0.8344 lr=0.000040 step/sec=1.63 | ETA 00:54:35\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:37,321] [   TRAIN]\u001b[0m - Epoch=2/6, Step=670/868 loss=0.5018 acc=0.8125 lr=0.000040 step/sec=1.63 | ETA 00:54:35\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:43,455] [   TRAIN]\u001b[0m - Epoch=2/6, Step=680/868 loss=0.5095 acc=0.8156 lr=0.000040 step/sec=1.63 | ETA 00:54:34\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:49,587] [   TRAIN]\u001b[0m - Epoch=2/6, Step=690/868 loss=0.5884 acc=0.7781 lr=0.000040 step/sec=1.63 | ETA 00:54:34\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:12:55,721] [   TRAIN]\u001b[0m - Epoch=2/6, Step=700/868 loss=0.5409 acc=0.8000 lr=0.000040 step/sec=1.63 | ETA 00:54:33\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:01,855] [   TRAIN]\u001b[0m - Epoch=2/6, Step=710/868 loss=0.5276 acc=0.8313 lr=0.000040 step/sec=1.63 | ETA 00:54:33\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:07,986] [   TRAIN]\u001b[0m - Epoch=2/6, Step=720/868 loss=0.5505 acc=0.8000 lr=0.000040 step/sec=1.63 | ETA 00:54:32\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:14,115] [   TRAIN]\u001b[0m - Epoch=2/6, Step=730/868 loss=0.5999 acc=0.8031 lr=0.000040 step/sec=1.63 | ETA 00:54:32\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:20,251] [   TRAIN]\u001b[0m - Epoch=2/6, Step=740/868 loss=0.4812 acc=0.8313 lr=0.000040 step/sec=1.63 | ETA 00:54:31\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:26,419] [   TRAIN]\u001b[0m - Epoch=2/6, Step=750/868 loss=0.5112 acc=0.7906 lr=0.000040 step/sec=1.62 | ETA 00:54:31\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:32,519] [   TRAIN]\u001b[0m - Epoch=2/6, Step=760/868 loss=0.6235 acc=0.7812 lr=0.000040 step/sec=1.64 | ETA 00:54:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:38,527] [   TRAIN]\u001b[0m - Epoch=2/6, Step=770/868 loss=0.4807 acc=0.8313 lr=0.000040 step/sec=1.66 | ETA 00:54:29\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:44,512] [   TRAIN]\u001b[0m - Epoch=2/6, Step=780/868 loss=0.4930 acc=0.8031 lr=0.000040 step/sec=1.67 | ETA 00:54:28\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:50,513] [   TRAIN]\u001b[0m - Epoch=2/6, Step=790/868 loss=0.4247 acc=0.8438 lr=0.000040 step/sec=1.67 | ETA 00:54:27\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:13:56,501] [   TRAIN]\u001b[0m - Epoch=2/6, Step=800/868 loss=0.4473 acc=0.8406 lr=0.000040 step/sec=1.67 | ETA 00:54:27\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:02,500] [   TRAIN]\u001b[0m - Epoch=2/6, Step=810/868 loss=0.5069 acc=0.8281 lr=0.000040 step/sec=1.67 | ETA 00:54:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:08,501] [   TRAIN]\u001b[0m - Epoch=2/6, Step=820/868 loss=0.6518 acc=0.7875 lr=0.000040 step/sec=1.67 | ETA 00:54:25\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:14,495] [   TRAIN]\u001b[0m - Epoch=2/6, Step=830/868 loss=0.6047 acc=0.7719 lr=0.000040 step/sec=1.67 | ETA 00:54:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:20,504] [   TRAIN]\u001b[0m - Epoch=2/6, Step=840/868 loss=0.5539 acc=0.8031 lr=0.000040 step/sec=1.66 | ETA 00:54:23\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:26,497] [   TRAIN]\u001b[0m - Epoch=2/6, Step=850/868 loss=0.5062 acc=0.8063 lr=0.000040 step/sec=1.67 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:32,503] [   TRAIN]\u001b[0m - Epoch=2/6, Step=860/868 loss=0.5164 acc=0.8313 lr=0.000040 step/sec=1.67 | ETA 00:54:22\u001b[0m\n",
      "\u001b[34m[2022-05-10 16:14:50,474] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7685\u001b[0mm\n",
      "\u001b[34m[2022-05-10 16:14:51,870] [    EVAL]\u001b[0m - Saving best model to ./ckpt\\best_model [best acc=0.7685]\u001b[0m\n",
      "\u001b[32m[2022-05-10 16:14:51,870] [    INFO]\u001b[0m - Saving model checkpoint to ./ckpt\\epoch_2\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:14:59,463] [   TRAIN]\u001b[0m - Epoch=3/6, Step=10/868 loss=0.3147 acc=0.9000 lr=0.000040 step/sec=0.67 | ETA 00:55:08\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:15:05,465] [   TRAIN]\u001b[0m - Epoch=3/6, Step=20/868 loss=0.3033 acc=0.8938 lr=0.000040 step/sec=1.67 | ETA 00:55:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:11,463] [   TRAIN]\u001b[0m - Epoch=3/6, Step=30/868 loss=0.3090 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:55:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:17,467] [   TRAIN]\u001b[0m - Epoch=3/6, Step=40/868 loss=0.2730 acc=0.9125 lr=0.000040 step/sec=1.67 | ETA 00:55:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:23,466] [   TRAIN]\u001b[0m - Epoch=3/6, Step=50/868 loss=0.3600 acc=0.8938 lr=0.000040 step/sec=1.67 | ETA 00:55:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:29,482] [   TRAIN]\u001b[0m - Epoch=3/6, Step=60/868 loss=0.3309 acc=0.8781 lr=0.000040 step/sec=1.66 | ETA 00:55:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:35,645] [   TRAIN]\u001b[0m - Epoch=3/6, Step=70/868 loss=0.2993 acc=0.8938 lr=0.000040 step/sec=1.62 | ETA 00:55:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:41,671] [   TRAIN]\u001b[0m - Epoch=3/6, Step=80/868 loss=0.2912 acc=0.8781 lr=0.000040 step/sec=1.66 | ETA 00:55:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:47,666] [   TRAIN]\u001b[0m - Epoch=3/6, Step=90/868 loss=0.3286 acc=0.8844 lr=0.000040 step/sec=1.67 | ETA 00:55:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:53,667] [   TRAIN]\u001b[0m - Epoch=3/6, Step=100/868 loss=0.3203 acc=0.8750 lr=0.000040 step/sec=1.67 | ETA 00:55:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:15:59,669] [   TRAIN]\u001b[0m - Epoch=3/6, Step=110/868 loss=0.2868 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:59\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:05,672] [   TRAIN]\u001b[0m - Epoch=3/6, Step=120/868 loss=0.2665 acc=0.9187 lr=0.000040 step/sec=1.67 | ETA 00:54:58\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:11,670] [   TRAIN]\u001b[0m - Epoch=3/6, Step=130/868 loss=0.2606 acc=0.9031 lr=0.000040 step/sec=1.67 | ETA 00:54:57\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:17,668] [   TRAIN]\u001b[0m - Epoch=3/6, Step=140/868 loss=0.3233 acc=0.8938 lr=0.000040 step/sec=1.67 | ETA 00:54:56\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:23,662] [   TRAIN]\u001b[0m - Epoch=3/6, Step=150/868 loss=0.3313 acc=0.8781 lr=0.000040 step/sec=1.67 | ETA 00:54:55\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:29,656] [   TRAIN]\u001b[0m - Epoch=3/6, Step=160/868 loss=0.2794 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:54\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:35,650] [   TRAIN]\u001b[0m - Epoch=3/6, Step=170/868 loss=0.3515 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:53\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:41,655] [   TRAIN]\u001b[0m - Epoch=3/6, Step=180/868 loss=0.3265 acc=0.8844 lr=0.000040 step/sec=1.67 | ETA 00:54:53\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:47,653] [   TRAIN]\u001b[0m - Epoch=3/6, Step=190/868 loss=0.2810 acc=0.9000 lr=0.000040 step/sec=1.67 | ETA 00:54:52\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:53,647] [   TRAIN]\u001b[0m - Epoch=3/6, Step=200/868 loss=0.2945 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:51\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:16:59,645] [   TRAIN]\u001b[0m - Epoch=3/6, Step=210/868 loss=0.2637 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:50\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:05,640] [   TRAIN]\u001b[0m - Epoch=3/6, Step=220/868 loss=0.2808 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:49\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:11,643] [   TRAIN]\u001b[0m - Epoch=3/6, Step=230/868 loss=0.3395 acc=0.8938 lr=0.000040 step/sec=1.67 | ETA 00:54:48\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:17,644] [   TRAIN]\u001b[0m - Epoch=3/6, Step=240/868 loss=0.3574 acc=0.8625 lr=0.000040 step/sec=1.67 | ETA 00:54:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:23,643] [   TRAIN]\u001b[0m - Epoch=3/6, Step=250/868 loss=0.3522 acc=0.8875 lr=0.000040 step/sec=1.67 | ETA 00:54:47\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:29,639] [   TRAIN]\u001b[0m - Epoch=3/6, Step=260/868 loss=0.3035 acc=0.8875 lr=0.000040 step/sec=1.67 | ETA 00:54:46\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:35,638] [   TRAIN]\u001b[0m - Epoch=3/6, Step=270/868 loss=0.3650 acc=0.8750 lr=0.000040 step/sec=1.67 | ETA 00:54:45\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:41,640] [   TRAIN]\u001b[0m - Epoch=3/6, Step=280/868 loss=0.2947 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:44\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:47,640] [   TRAIN]\u001b[0m - Epoch=3/6, Step=290/868 loss=0.3398 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:43\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:53,640] [   TRAIN]\u001b[0m - Epoch=3/6, Step=300/868 loss=0.3598 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:43\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:17:59,643] [   TRAIN]\u001b[0m - Epoch=3/6, Step=310/868 loss=0.3669 acc=0.8688 lr=0.000040 step/sec=1.67 | ETA 00:54:42\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:05,640] [   TRAIN]\u001b[0m - Epoch=3/6, Step=320/868 loss=0.3490 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:41\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:11,631] [   TRAIN]\u001b[0m - Epoch=3/6, Step=330/868 loss=0.3664 acc=0.8938 lr=0.000040 step/sec=1.67 | ETA 00:54:40\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:17,631] [   TRAIN]\u001b[0m - Epoch=3/6, Step=340/868 loss=0.3437 acc=0.8750 lr=0.000040 step/sec=1.67 | ETA 00:54:40\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:23,631] [   TRAIN]\u001b[0m - Epoch=3/6, Step=350/868 loss=0.3527 acc=0.8594 lr=0.000040 step/sec=1.67 | ETA 00:54:39\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:29,628] [   TRAIN]\u001b[0m - Epoch=3/6, Step=360/868 loss=0.3805 acc=0.8625 lr=0.000040 step/sec=1.67 | ETA 00:54:38\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:35,625] [   TRAIN]\u001b[0m - Epoch=3/6, Step=370/868 loss=0.3395 acc=0.8781 lr=0.000040 step/sec=1.67 | ETA 00:54:37\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:41,625] [   TRAIN]\u001b[0m - Epoch=3/6, Step=380/868 loss=0.3486 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:37\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:47,624] [   TRAIN]\u001b[0m - Epoch=3/6, Step=390/868 loss=0.2862 acc=0.9031 lr=0.000040 step/sec=1.67 | ETA 00:54:36\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:53,630] [   TRAIN]\u001b[0m - Epoch=3/6, Step=400/868 loss=0.3625 acc=0.8656 lr=0.000040 step/sec=1.67 | ETA 00:54:35\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:18:59,628] [   TRAIN]\u001b[0m - Epoch=3/6, Step=410/868 loss=0.2489 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:35\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:05,627] [   TRAIN]\u001b[0m - Epoch=3/6, Step=420/868 loss=0.3455 acc=0.8625 lr=0.000040 step/sec=1.67 | ETA 00:54:34\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:11,626] [   TRAIN]\u001b[0m - Epoch=3/6, Step=430/868 loss=0.3489 acc=0.8750 lr=0.000040 step/sec=1.67 | ETA 00:54:33\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:17,635] [   TRAIN]\u001b[0m - Epoch=3/6, Step=440/868 loss=0.3353 acc=0.8719 lr=0.000040 step/sec=1.66 | ETA 00:54:32\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:23,633] [   TRAIN]\u001b[0m - Epoch=3/6, Step=450/868 loss=0.3046 acc=0.8812 lr=0.000040 step/sec=1.67 | ETA 00:54:32\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:29,635] [   TRAIN]\u001b[0m - Epoch=3/6, Step=460/868 loss=0.3360 acc=0.8688 lr=0.000040 step/sec=1.67 | ETA 00:54:31\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:35,626] [   TRAIN]\u001b[0m - Epoch=3/6, Step=470/868 loss=0.3933 acc=0.8500 lr=0.000040 step/sec=1.67 | ETA 00:54:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:41,629] [   TRAIN]\u001b[0m - Epoch=3/6, Step=480/868 loss=0.3472 acc=0.8625 lr=0.000040 step/sec=1.67 | ETA 00:54:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:47,630] [   TRAIN]\u001b[0m - Epoch=3/6, Step=490/868 loss=0.3571 acc=0.8688 lr=0.000040 step/sec=1.67 | ETA 00:54:29\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:53,635] [   TRAIN]\u001b[0m - Epoch=3/6, Step=500/868 loss=0.2593 acc=0.9031 lr=0.000040 step/sec=1.67 | ETA 00:54:28\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:19:59,631] [   TRAIN]\u001b[0m - Epoch=3/6, Step=510/868 loss=0.3268 acc=0.8844 lr=0.000040 step/sec=1.67 | ETA 00:54:28\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:05,629] [   TRAIN]\u001b[0m - Epoch=3/6, Step=520/868 loss=0.2517 acc=0.9250 lr=0.000040 step/sec=1.67 | ETA 00:54:27\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:11,632] [   TRAIN]\u001b[0m - Epoch=3/6, Step=530/868 loss=0.2888 acc=0.9031 lr=0.000040 step/sec=1.67 | ETA 00:54:27\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:17,620] [   TRAIN]\u001b[0m - Epoch=3/6, Step=540/868 loss=0.3666 acc=0.8562 lr=0.000040 step/sec=1.67 | ETA 00:54:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:23,616] [   TRAIN]\u001b[0m - Epoch=3/6, Step=550/868 loss=0.3273 acc=0.8844 lr=0.000040 step/sec=1.67 | ETA 00:54:25\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:29,623] [   TRAIN]\u001b[0m - Epoch=3/6, Step=560/868 loss=0.4252 acc=0.8594 lr=0.000040 step/sec=1.66 | ETA 00:54:25\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:35,677] [   TRAIN]\u001b[0m - Epoch=3/6, Step=570/868 loss=0.3229 acc=0.8625 lr=0.000040 step/sec=1.65 | ETA 00:54:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:41,716] [   TRAIN]\u001b[0m - Epoch=3/6, Step=580/868 loss=0.3385 acc=0.8969 lr=0.000040 step/sec=1.66 | ETA 00:54:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:47,727] [   TRAIN]\u001b[0m - Epoch=3/6, Step=590/868 loss=0.3839 acc=0.8719 lr=0.000040 step/sec=1.66 | ETA 00:54:23\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:20:53,723] [   TRAIN]\u001b[0m - Epoch=3/6, Step=600/868 loss=0.3856 acc=0.8750 lr=0.000040 step/sec=1.67 | ETA 00:54:22\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:20:59,725] [   TRAIN]\u001b[0m - Epoch=3/6, Step=610/868 loss=0.4173 acc=0.8531 lr=0.000040 step/sec=1.67 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:05,727] [   TRAIN]\u001b[0m - Epoch=3/6, Step=620/868 loss=0.3158 acc=0.8875 lr=0.000040 step/sec=1.67 | ETA 00:54:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:11,724] [   TRAIN]\u001b[0m - Epoch=3/6, Step=630/868 loss=0.4295 acc=0.8313 lr=0.000040 step/sec=1.67 | ETA 00:54:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:17,723] [   TRAIN]\u001b[0m - Epoch=3/6, Step=640/868 loss=0.3607 acc=0.8812 lr=0.000040 step/sec=1.67 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:23,720] [   TRAIN]\u001b[0m - Epoch=3/6, Step=650/868 loss=0.2946 acc=0.8844 lr=0.000040 step/sec=1.67 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:29,721] [   TRAIN]\u001b[0m - Epoch=3/6, Step=660/868 loss=0.3692 acc=0.8656 lr=0.000040 step/sec=1.67 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:35,726] [   TRAIN]\u001b[0m - Epoch=3/6, Step=670/868 loss=0.3415 acc=0.8812 lr=0.000040 step/sec=1.67 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:41,725] [   TRAIN]\u001b[0m - Epoch=3/6, Step=680/868 loss=0.3515 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:47,725] [   TRAIN]\u001b[0m - Epoch=3/6, Step=690/868 loss=0.3675 acc=0.8625 lr=0.000040 step/sec=1.67 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:53,720] [   TRAIN]\u001b[0m - Epoch=3/6, Step=700/868 loss=0.3073 acc=0.9062 lr=0.000040 step/sec=1.67 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:21:59,712] [   TRAIN]\u001b[0m - Epoch=3/6, Step=710/868 loss=0.4026 acc=0.8531 lr=0.000040 step/sec=1.67 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:05,711] [   TRAIN]\u001b[0m - Epoch=3/6, Step=720/868 loss=0.4196 acc=0.8469 lr=0.000040 step/sec=1.67 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:11,710] [   TRAIN]\u001b[0m - Epoch=3/6, Step=730/868 loss=0.3270 acc=0.8656 lr=0.000040 step/sec=1.67 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:17,707] [   TRAIN]\u001b[0m - Epoch=3/6, Step=740/868 loss=0.3768 acc=0.8750 lr=0.000040 step/sec=1.67 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:23,707] [   TRAIN]\u001b[0m - Epoch=3/6, Step=750/868 loss=0.4011 acc=0.8688 lr=0.000040 step/sec=1.67 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:29,702] [   TRAIN]\u001b[0m - Epoch=3/6, Step=760/868 loss=0.4009 acc=0.8531 lr=0.000040 step/sec=1.67 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:35,697] [   TRAIN]\u001b[0m - Epoch=3/6, Step=770/868 loss=0.3188 acc=0.8875 lr=0.000040 step/sec=1.67 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:41,697] [   TRAIN]\u001b[0m - Epoch=3/6, Step=780/868 loss=0.3219 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:47,693] [   TRAIN]\u001b[0m - Epoch=3/6, Step=790/868 loss=0.3394 acc=0.8688 lr=0.000040 step/sec=1.67 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:53,692] [   TRAIN]\u001b[0m - Epoch=3/6, Step=800/868 loss=0.3495 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:22:59,696] [   TRAIN]\u001b[0m - Epoch=3/6, Step=810/868 loss=0.4003 acc=0.8438 lr=0.000040 step/sec=1.67 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:23:05,698] [   TRAIN]\u001b[0m - Epoch=3/6, Step=820/868 loss=0.2889 acc=0.8938 lr=0.000040 step/sec=1.67 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:23:11,695] [   TRAIN]\u001b[0m - Epoch=3/6, Step=830/868 loss=0.3599 acc=0.8719 lr=0.000040 step/sec=1.67 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:23:17,691] [   TRAIN]\u001b[0m - Epoch=3/6, Step=840/868 loss=0.3509 acc=0.8781 lr=0.000040 step/sec=1.67 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:23:23,680] [   TRAIN]\u001b[0m - Epoch=3/6, Step=850/868 loss=0.4655 acc=0.8531 lr=0.000040 step/sec=1.67 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:23:29,679] [   TRAIN]\u001b[0m - Epoch=3/6, Step=860/868 loss=0.3307 acc=0.8875 lr=0.000040 step/sec=1.67 | ETA 00:54:09\u001b[0m\n",
      "\u001b[34m[2022-05-10 16:23:47,614] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7665\u001b[0mm\n",
      "\u001b[32m[2022-05-10 16:23:47,614] [    INFO]\u001b[0m - Saving model checkpoint to ./ckpt\\epoch_3\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:23:55,337] [   TRAIN]\u001b[0m - Epoch=4/6, Step=10/868 loss=0.1856 acc=0.9313 lr=0.000040 step/sec=0.70 | ETA 00:54:37\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:01,334] [   TRAIN]\u001b[0m - Epoch=4/6, Step=20/868 loss=0.1900 acc=0.9375 lr=0.000040 step/sec=1.67 | ETA 00:54:37\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:07,324] [   TRAIN]\u001b[0m - Epoch=4/6, Step=30/868 loss=0.2267 acc=0.9187 lr=0.000040 step/sec=1.67 | ETA 00:54:36\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:13,316] [   TRAIN]\u001b[0m - Epoch=4/6, Step=40/868 loss=0.1842 acc=0.9375 lr=0.000040 step/sec=1.67 | ETA 00:54:36\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:19,315] [   TRAIN]\u001b[0m - Epoch=4/6, Step=50/868 loss=0.1889 acc=0.9469 lr=0.000040 step/sec=1.67 | ETA 00:54:35\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:25,313] [   TRAIN]\u001b[0m - Epoch=4/6, Step=60/868 loss=0.2107 acc=0.9313 lr=0.000040 step/sec=1.67 | ETA 00:54:34\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:31,304] [   TRAIN]\u001b[0m - Epoch=4/6, Step=70/868 loss=0.1732 acc=0.9531 lr=0.000040 step/sec=1.67 | ETA 00:54:34\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:37,301] [   TRAIN]\u001b[0m - Epoch=4/6, Step=80/868 loss=0.1854 acc=0.9187 lr=0.000040 step/sec=1.67 | ETA 00:54:33\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:43,300] [   TRAIN]\u001b[0m - Epoch=4/6, Step=90/868 loss=0.1869 acc=0.9469 lr=0.000040 step/sec=1.67 | ETA 00:54:33\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:49,301] [   TRAIN]\u001b[0m - Epoch=4/6, Step=100/868 loss=0.1053 acc=0.9688 lr=0.000040 step/sec=1.67 | ETA 00:54:32\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:24:55,299] [   TRAIN]\u001b[0m - Epoch=4/6, Step=110/868 loss=0.2250 acc=0.9281 lr=0.000040 step/sec=1.67 | ETA 00:54:32\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:01,292] [   TRAIN]\u001b[0m - Epoch=4/6, Step=120/868 loss=0.1644 acc=0.9437 lr=0.000040 step/sec=1.67 | ETA 00:54:31\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:07,291] [   TRAIN]\u001b[0m - Epoch=4/6, Step=130/868 loss=0.1760 acc=0.9469 lr=0.000040 step/sec=1.67 | ETA 00:54:31\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:13,289] [   TRAIN]\u001b[0m - Epoch=4/6, Step=140/868 loss=0.1365 acc=0.9625 lr=0.000040 step/sec=1.67 | ETA 00:54:30\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:19,285] [   TRAIN]\u001b[0m - Epoch=4/6, Step=150/868 loss=0.2066 acc=0.9156 lr=0.000040 step/sec=1.67 | ETA 00:54:29\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:25,273] [   TRAIN]\u001b[0m - Epoch=4/6, Step=160/868 loss=0.1624 acc=0.9563 lr=0.000040 step/sec=1.67 | ETA 00:54:29\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:31,273] [   TRAIN]\u001b[0m - Epoch=4/6, Step=170/868 loss=0.2021 acc=0.9406 lr=0.000040 step/sec=1.67 | ETA 00:54:28\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:37,271] [   TRAIN]\u001b[0m - Epoch=4/6, Step=180/868 loss=0.2343 acc=0.9000 lr=0.000040 step/sec=1.67 | ETA 00:54:28\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:43,265] [   TRAIN]\u001b[0m - Epoch=4/6, Step=190/868 loss=0.1601 acc=0.9437 lr=0.000040 step/sec=1.67 | ETA 00:54:27\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:49,272] [   TRAIN]\u001b[0m - Epoch=4/6, Step=200/868 loss=0.1968 acc=0.9187 lr=0.000040 step/sec=1.66 | ETA 00:54:27\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:25:55,274] [   TRAIN]\u001b[0m - Epoch=4/6, Step=210/868 loss=0.2627 acc=0.9031 lr=0.000040 step/sec=1.67 | ETA 00:54:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:01,288] [   TRAIN]\u001b[0m - Epoch=4/6, Step=220/868 loss=0.2359 acc=0.9250 lr=0.000040 step/sec=1.66 | ETA 00:54:26\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:07,330] [   TRAIN]\u001b[0m - Epoch=4/6, Step=230/868 loss=0.1742 acc=0.9437 lr=0.000040 step/sec=1.66 | ETA 00:54:25\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:13,364] [   TRAIN]\u001b[0m - Epoch=4/6, Step=240/868 loss=0.1833 acc=0.9406 lr=0.000040 step/sec=1.66 | ETA 00:54:25\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:19,395] [   TRAIN]\u001b[0m - Epoch=4/6, Step=250/868 loss=0.1326 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:25\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:25,425] [   TRAIN]\u001b[0m - Epoch=4/6, Step=260/868 loss=0.2349 acc=0.9281 lr=0.000040 step/sec=1.66 | ETA 00:54:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:31,446] [   TRAIN]\u001b[0m - Epoch=4/6, Step=270/868 loss=0.2044 acc=0.9281 lr=0.000040 step/sec=1.66 | ETA 00:54:24\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:37,478] [   TRAIN]\u001b[0m - Epoch=4/6, Step=280/868 loss=0.1844 acc=0.9313 lr=0.000040 step/sec=1.66 | ETA 00:54:23\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:43,503] [   TRAIN]\u001b[0m - Epoch=4/6, Step=290/868 loss=0.2085 acc=0.9219 lr=0.000040 step/sec=1.66 | ETA 00:54:23\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:49,529] [   TRAIN]\u001b[0m - Epoch=4/6, Step=300/868 loss=0.1507 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:26:55,562] [   TRAIN]\u001b[0m - Epoch=4/6, Step=310/868 loss=0.2556 acc=0.9000 lr=0.000040 step/sec=1.66 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:01,589] [   TRAIN]\u001b[0m - Epoch=4/6, Step=320/868 loss=0.2936 acc=0.9094 lr=0.000040 step/sec=1.66 | ETA 00:54:22\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:27:07,613] [   TRAIN]\u001b[0m - Epoch=4/6, Step=330/868 loss=0.2148 acc=0.9313 lr=0.000040 step/sec=1.66 | ETA 00:54:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:13,646] [   TRAIN]\u001b[0m - Epoch=4/6, Step=340/868 loss=0.1989 acc=0.9375 lr=0.000040 step/sec=1.66 | ETA 00:54:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:19,667] [   TRAIN]\u001b[0m - Epoch=4/6, Step=350/868 loss=0.2010 acc=0.9187 lr=0.000040 step/sec=1.66 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:25,697] [   TRAIN]\u001b[0m - Epoch=4/6, Step=360/868 loss=0.2569 acc=0.9250 lr=0.000040 step/sec=1.66 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:31,723] [   TRAIN]\u001b[0m - Epoch=4/6, Step=370/868 loss=0.1931 acc=0.9250 lr=0.000040 step/sec=1.66 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:37,731] [   TRAIN]\u001b[0m - Epoch=4/6, Step=380/868 loss=0.1633 acc=0.9437 lr=0.000040 step/sec=1.66 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:43,731] [   TRAIN]\u001b[0m - Epoch=4/6, Step=390/868 loss=0.1640 acc=0.9406 lr=0.000040 step/sec=1.67 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:49,730] [   TRAIN]\u001b[0m - Epoch=4/6, Step=400/868 loss=0.1882 acc=0.9469 lr=0.000040 step/sec=1.67 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:27:55,731] [   TRAIN]\u001b[0m - Epoch=4/6, Step=410/868 loss=0.2138 acc=0.9406 lr=0.000040 step/sec=1.67 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:01,725] [   TRAIN]\u001b[0m - Epoch=4/6, Step=420/868 loss=0.1541 acc=0.9500 lr=0.000040 step/sec=1.67 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:07,716] [   TRAIN]\u001b[0m - Epoch=4/6, Step=430/868 loss=0.1881 acc=0.9313 lr=0.000040 step/sec=1.67 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:13,716] [   TRAIN]\u001b[0m - Epoch=4/6, Step=440/868 loss=0.1567 acc=0.9406 lr=0.000040 step/sec=1.67 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:19,711] [   TRAIN]\u001b[0m - Epoch=4/6, Step=450/868 loss=0.2279 acc=0.9125 lr=0.000040 step/sec=1.67 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:25,712] [   TRAIN]\u001b[0m - Epoch=4/6, Step=460/868 loss=0.2010 acc=0.9375 lr=0.000040 step/sec=1.67 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:31,861] [   TRAIN]\u001b[0m - Epoch=4/6, Step=470/868 loss=0.2137 acc=0.9187 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:37,937] [   TRAIN]\u001b[0m - Epoch=4/6, Step=480/868 loss=0.2066 acc=0.9156 lr=0.000040 step/sec=1.65 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:43,936] [   TRAIN]\u001b[0m - Epoch=4/6, Step=490/868 loss=0.2036 acc=0.9219 lr=0.000040 step/sec=1.67 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:49,928] [   TRAIN]\u001b[0m - Epoch=4/6, Step=500/868 loss=0.2194 acc=0.9187 lr=0.000040 step/sec=1.67 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:28:55,929] [   TRAIN]\u001b[0m - Epoch=4/6, Step=510/868 loss=0.1916 acc=0.9437 lr=0.000040 step/sec=1.67 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:01,931] [   TRAIN]\u001b[0m - Epoch=4/6, Step=520/868 loss=0.2273 acc=0.9062 lr=0.000040 step/sec=1.67 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:07,931] [   TRAIN]\u001b[0m - Epoch=4/6, Step=530/868 loss=0.1853 acc=0.9406 lr=0.000040 step/sec=1.67 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:13,925] [   TRAIN]\u001b[0m - Epoch=4/6, Step=540/868 loss=0.2121 acc=0.9344 lr=0.000040 step/sec=1.67 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:19,925] [   TRAIN]\u001b[0m - Epoch=4/6, Step=550/868 loss=0.1894 acc=0.9500 lr=0.000040 step/sec=1.67 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:25,931] [   TRAIN]\u001b[0m - Epoch=4/6, Step=560/868 loss=0.2526 acc=0.9125 lr=0.000040 step/sec=1.67 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:31,931] [   TRAIN]\u001b[0m - Epoch=4/6, Step=570/868 loss=0.1737 acc=0.9375 lr=0.000040 step/sec=1.67 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:37,932] [   TRAIN]\u001b[0m - Epoch=4/6, Step=580/868 loss=0.2846 acc=0.8969 lr=0.000040 step/sec=1.67 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:43,935] [   TRAIN]\u001b[0m - Epoch=4/6, Step=590/868 loss=0.2679 acc=0.9031 lr=0.000040 step/sec=1.67 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:49,935] [   TRAIN]\u001b[0m - Epoch=4/6, Step=600/868 loss=0.2336 acc=0.9281 lr=0.000040 step/sec=1.67 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:29:55,934] [   TRAIN]\u001b[0m - Epoch=4/6, Step=610/868 loss=0.2520 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:01,935] [   TRAIN]\u001b[0m - Epoch=4/6, Step=620/868 loss=0.1770 acc=0.9375 lr=0.000040 step/sec=1.67 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:07,971] [   TRAIN]\u001b[0m - Epoch=4/6, Step=630/868 loss=0.2203 acc=0.9281 lr=0.000040 step/sec=1.66 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:13,965] [   TRAIN]\u001b[0m - Epoch=4/6, Step=640/868 loss=0.3202 acc=0.9000 lr=0.000040 step/sec=1.67 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:19,970] [   TRAIN]\u001b[0m - Epoch=4/6, Step=650/868 loss=0.1879 acc=0.9281 lr=0.000040 step/sec=1.67 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:25,968] [   TRAIN]\u001b[0m - Epoch=4/6, Step=660/868 loss=0.2151 acc=0.9344 lr=0.000040 step/sec=1.67 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:31,969] [   TRAIN]\u001b[0m - Epoch=4/6, Step=670/868 loss=0.2674 acc=0.8969 lr=0.000040 step/sec=1.67 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:37,963] [   TRAIN]\u001b[0m - Epoch=4/6, Step=680/868 loss=0.2204 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:43,955] [   TRAIN]\u001b[0m - Epoch=4/6, Step=690/868 loss=0.1750 acc=0.9313 lr=0.000040 step/sec=1.67 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:49,954] [   TRAIN]\u001b[0m - Epoch=4/6, Step=700/868 loss=0.1638 acc=0.9313 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:30:55,947] [   TRAIN]\u001b[0m - Epoch=4/6, Step=710/868 loss=0.2274 acc=0.9187 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:01,937] [   TRAIN]\u001b[0m - Epoch=4/6, Step=720/868 loss=0.1251 acc=0.9656 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:07,930] [   TRAIN]\u001b[0m - Epoch=4/6, Step=730/868 loss=0.1806 acc=0.9281 lr=0.000040 step/sec=1.67 | ETA 00:54:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:13,923] [   TRAIN]\u001b[0m - Epoch=4/6, Step=740/868 loss=0.2499 acc=0.9250 lr=0.000040 step/sec=1.67 | ETA 00:54:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:19,909] [   TRAIN]\u001b[0m - Epoch=4/6, Step=750/868 loss=0.2199 acc=0.9125 lr=0.000040 step/sec=1.67 | ETA 00:54:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:25,898] [   TRAIN]\u001b[0m - Epoch=4/6, Step=760/868 loss=0.2105 acc=0.9469 lr=0.000040 step/sec=1.67 | ETA 00:54:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:31,895] [   TRAIN]\u001b[0m - Epoch=4/6, Step=770/868 loss=0.2126 acc=0.9250 lr=0.000040 step/sec=1.67 | ETA 00:54:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:37,890] [   TRAIN]\u001b[0m - Epoch=4/6, Step=780/868 loss=0.2939 acc=0.8906 lr=0.000040 step/sec=1.67 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:43,881] [   TRAIN]\u001b[0m - Epoch=4/6, Step=790/868 loss=0.1546 acc=0.9469 lr=0.000040 step/sec=1.67 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:49,881] [   TRAIN]\u001b[0m - Epoch=4/6, Step=800/868 loss=0.1852 acc=0.9500 lr=0.000040 step/sec=1.67 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:31:55,876] [   TRAIN]\u001b[0m - Epoch=4/6, Step=810/868 loss=0.2001 acc=0.9187 lr=0.000040 step/sec=1.67 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:01,877] [   TRAIN]\u001b[0m - Epoch=4/6, Step=820/868 loss=0.2951 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:07,914] [   TRAIN]\u001b[0m - Epoch=4/6, Step=830/868 loss=0.1724 acc=0.9344 lr=0.000040 step/sec=1.66 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:13,912] [   TRAIN]\u001b[0m - Epoch=4/6, Step=840/868 loss=0.2179 acc=0.9094 lr=0.000040 step/sec=1.67 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:19,917] [   TRAIN]\u001b[0m - Epoch=4/6, Step=850/868 loss=0.2041 acc=0.9344 lr=0.000040 step/sec=1.67 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:25,913] [   TRAIN]\u001b[0m - Epoch=4/6, Step=860/868 loss=0.2171 acc=0.9219 lr=0.000040 step/sec=1.67 | ETA 00:54:01\u001b[0m\n",
      "\u001b[34m[2022-05-10 16:32:44,058] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7640\u001b[0mm\n",
      "\u001b[32m[2022-05-10 16:32:44,059] [    INFO]\u001b[0m - Saving model checkpoint to ./ckpt\\epoch_4\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:51,697] [   TRAIN]\u001b[0m - Epoch=5/6, Step=10/868 loss=0.1091 acc=0.9563 lr=0.000040 step/sec=0.70 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:32:57,723] [   TRAIN]\u001b[0m - Epoch=5/6, Step=20/868 loss=0.0913 acc=0.9719 lr=0.000040 step/sec=1.66 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:03,752] [   TRAIN]\u001b[0m - Epoch=5/6, Step=30/868 loss=0.1046 acc=0.9750 lr=0.000040 step/sec=1.66 | ETA 00:54:22\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:09,778] [   TRAIN]\u001b[0m - Epoch=5/6, Step=40/868 loss=0.1157 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:21\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:33:15,800] [   TRAIN]\u001b[0m - Epoch=5/6, Step=50/868 loss=0.1035 acc=0.9594 lr=0.000040 step/sec=1.66 | ETA 00:54:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:21,830] [   TRAIN]\u001b[0m - Epoch=5/6, Step=60/868 loss=0.0810 acc=0.9719 lr=0.000040 step/sec=1.66 | ETA 00:54:21\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:27,848] [   TRAIN]\u001b[0m - Epoch=5/6, Step=70/868 loss=0.0727 acc=0.9844 lr=0.000040 step/sec=1.66 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:33,871] [   TRAIN]\u001b[0m - Epoch=5/6, Step=80/868 loss=0.1170 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:39,895] [   TRAIN]\u001b[0m - Epoch=5/6, Step=90/868 loss=0.1638 acc=0.9375 lr=0.000040 step/sec=1.66 | ETA 00:54:20\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:45,913] [   TRAIN]\u001b[0m - Epoch=5/6, Step=100/868 loss=0.1179 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:51,946] [   TRAIN]\u001b[0m - Epoch=5/6, Step=110/868 loss=0.0933 acc=0.9750 lr=0.000040 step/sec=1.66 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:33:57,965] [   TRAIN]\u001b[0m - Epoch=5/6, Step=120/868 loss=0.1137 acc=0.9594 lr=0.000040 step/sec=1.66 | ETA 00:54:19\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:04,006] [   TRAIN]\u001b[0m - Epoch=5/6, Step=130/868 loss=0.0970 acc=0.9719 lr=0.000040 step/sec=1.66 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:10,057] [   TRAIN]\u001b[0m - Epoch=5/6, Step=140/868 loss=0.0976 acc=0.9719 lr=0.000040 step/sec=1.65 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:16,088] [   TRAIN]\u001b[0m - Epoch=5/6, Step=150/868 loss=0.0698 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:22,115] [   TRAIN]\u001b[0m - Epoch=5/6, Step=160/868 loss=0.0728 acc=0.9781 lr=0.000040 step/sec=1.66 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:28,341] [   TRAIN]\u001b[0m - Epoch=5/6, Step=170/868 loss=0.0840 acc=0.9688 lr=0.000040 step/sec=1.61 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:34,362] [   TRAIN]\u001b[0m - Epoch=5/6, Step=180/868 loss=0.1488 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:40,390] [   TRAIN]\u001b[0m - Epoch=5/6, Step=190/868 loss=0.0978 acc=0.9656 lr=0.000040 step/sec=1.66 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:46,418] [   TRAIN]\u001b[0m - Epoch=5/6, Step=200/868 loss=0.0816 acc=0.9781 lr=0.000040 step/sec=1.66 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:52,435] [   TRAIN]\u001b[0m - Epoch=5/6, Step=210/868 loss=0.1237 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:34:58,461] [   TRAIN]\u001b[0m - Epoch=5/6, Step=220/868 loss=0.0913 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:04,482] [   TRAIN]\u001b[0m - Epoch=5/6, Step=230/868 loss=0.1894 acc=0.9250 lr=0.000040 step/sec=1.66 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:10,498] [   TRAIN]\u001b[0m - Epoch=5/6, Step=240/868 loss=0.0946 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:16,516] [   TRAIN]\u001b[0m - Epoch=5/6, Step=250/868 loss=0.1049 acc=0.9594 lr=0.000040 step/sec=1.66 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:22,542] [   TRAIN]\u001b[0m - Epoch=5/6, Step=260/868 loss=0.1900 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:28,563] [   TRAIN]\u001b[0m - Epoch=5/6, Step=270/868 loss=0.1172 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:34,587] [   TRAIN]\u001b[0m - Epoch=5/6, Step=280/868 loss=0.0938 acc=0.9656 lr=0.000040 step/sec=1.66 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:40,615] [   TRAIN]\u001b[0m - Epoch=5/6, Step=290/868 loss=0.1748 acc=0.9313 lr=0.000040 step/sec=1.66 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:46,631] [   TRAIN]\u001b[0m - Epoch=5/6, Step=300/868 loss=0.1457 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:52,657] [   TRAIN]\u001b[0m - Epoch=5/6, Step=310/868 loss=0.0994 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:35:58,686] [   TRAIN]\u001b[0m - Epoch=5/6, Step=320/868 loss=0.1180 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:04,732] [   TRAIN]\u001b[0m - Epoch=5/6, Step=330/868 loss=0.1134 acc=0.9594 lr=0.000040 step/sec=1.65 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:10,770] [   TRAIN]\u001b[0m - Epoch=5/6, Step=340/868 loss=0.0850 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:16,792] [   TRAIN]\u001b[0m - Epoch=5/6, Step=350/868 loss=0.0969 acc=0.9719 lr=0.000040 step/sec=1.66 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:22,817] [   TRAIN]\u001b[0m - Epoch=5/6, Step=360/868 loss=0.1099 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:28,839] [   TRAIN]\u001b[0m - Epoch=5/6, Step=370/868 loss=0.0796 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:34,857] [   TRAIN]\u001b[0m - Epoch=5/6, Step=380/868 loss=0.0850 acc=0.9750 lr=0.000040 step/sec=1.66 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:40,890] [   TRAIN]\u001b[0m - Epoch=5/6, Step=390/868 loss=0.1182 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:46,910] [   TRAIN]\u001b[0m - Epoch=5/6, Step=400/868 loss=0.1437 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:52,926] [   TRAIN]\u001b[0m - Epoch=5/6, Step=410/868 loss=0.0750 acc=0.9812 lr=0.000040 step/sec=1.66 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:36:58,954] [   TRAIN]\u001b[0m - Epoch=5/6, Step=420/868 loss=0.1243 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:04,969] [   TRAIN]\u001b[0m - Epoch=5/6, Step=430/868 loss=0.1177 acc=0.9656 lr=0.000040 step/sec=1.66 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:10,995] [   TRAIN]\u001b[0m - Epoch=5/6, Step=440/868 loss=0.1242 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:17,018] [   TRAIN]\u001b[0m - Epoch=5/6, Step=450/868 loss=0.1541 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:23,037] [   TRAIN]\u001b[0m - Epoch=5/6, Step=460/868 loss=0.0943 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:29,084] [   TRAIN]\u001b[0m - Epoch=5/6, Step=470/868 loss=0.1414 acc=0.9531 lr=0.000040 step/sec=1.65 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:35,107] [   TRAIN]\u001b[0m - Epoch=5/6, Step=480/868 loss=0.1429 acc=0.9437 lr=0.000040 step/sec=1.66 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:41,123] [   TRAIN]\u001b[0m - Epoch=5/6, Step=490/868 loss=0.1092 acc=0.9594 lr=0.000040 step/sec=1.66 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:47,151] [   TRAIN]\u001b[0m - Epoch=5/6, Step=500/868 loss=0.0995 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:53,171] [   TRAIN]\u001b[0m - Epoch=5/6, Step=510/868 loss=0.1185 acc=0.9594 lr=0.000040 step/sec=1.66 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:37:59,200] [   TRAIN]\u001b[0m - Epoch=5/6, Step=520/868 loss=0.1279 acc=0.9594 lr=0.000040 step/sec=1.66 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:05,254] [   TRAIN]\u001b[0m - Epoch=5/6, Step=530/868 loss=0.1719 acc=0.9437 lr=0.000040 step/sec=1.65 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:11,289] [   TRAIN]\u001b[0m - Epoch=5/6, Step=540/868 loss=0.1200 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:17,312] [   TRAIN]\u001b[0m - Epoch=5/6, Step=550/868 loss=0.1105 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:23,336] [   TRAIN]\u001b[0m - Epoch=5/6, Step=560/868 loss=0.0943 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:29,357] [   TRAIN]\u001b[0m - Epoch=5/6, Step=570/868 loss=0.1408 acc=0.9500 lr=0.000040 step/sec=1.66 | ETA 00:54:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:35,378] [   TRAIN]\u001b[0m - Epoch=5/6, Step=580/868 loss=0.1413 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:41,405] [   TRAIN]\u001b[0m - Epoch=5/6, Step=590/868 loss=0.1394 acc=0.9500 lr=0.000040 step/sec=1.66 | ETA 00:54:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:47,423] [   TRAIN]\u001b[0m - Epoch=5/6, Step=600/868 loss=0.1063 acc=0.9625 lr=0.000040 step/sec=1.66 | ETA 00:54:05\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:53,443] [   TRAIN]\u001b[0m - Epoch=5/6, Step=610/868 loss=0.1550 acc=0.9375 lr=0.000040 step/sec=1.66 | ETA 00:54:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:38:59,468] [   TRAIN]\u001b[0m - Epoch=5/6, Step=620/868 loss=0.1187 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:05,482] [   TRAIN]\u001b[0m - Epoch=5/6, Step=630/868 loss=0.1466 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:04\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:39:11,503] [   TRAIN]\u001b[0m - Epoch=5/6, Step=640/868 loss=0.1070 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:04\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:17,520] [   TRAIN]\u001b[0m - Epoch=5/6, Step=650/868 loss=0.1810 acc=0.9344 lr=0.000040 step/sec=1.66 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:23,540] [   TRAIN]\u001b[0m - Epoch=5/6, Step=660/868 loss=0.1085 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:29,557] [   TRAIN]\u001b[0m - Epoch=5/6, Step=670/868 loss=0.1506 acc=0.9437 lr=0.000040 step/sec=1.66 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:35,585] [   TRAIN]\u001b[0m - Epoch=5/6, Step=680/868 loss=0.1843 acc=0.9313 lr=0.000040 step/sec=1.66 | ETA 00:54:03\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:41,610] [   TRAIN]\u001b[0m - Epoch=5/6, Step=690/868 loss=0.1624 acc=0.9281 lr=0.000040 step/sec=1.66 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:47,637] [   TRAIN]\u001b[0m - Epoch=5/6, Step=700/868 loss=0.2495 acc=0.9125 lr=0.000040 step/sec=1.66 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:53,659] [   TRAIN]\u001b[0m - Epoch=5/6, Step=710/868 loss=0.1141 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:39:59,690] [   TRAIN]\u001b[0m - Epoch=5/6, Step=720/868 loss=0.1918 acc=0.9531 lr=0.000040 step/sec=1.66 | ETA 00:54:02\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:05,783] [   TRAIN]\u001b[0m - Epoch=5/6, Step=730/868 loss=0.1922 acc=0.9281 lr=0.000040 step/sec=1.64 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:11,817] [   TRAIN]\u001b[0m - Epoch=5/6, Step=740/868 loss=0.1367 acc=0.9688 lr=0.000040 step/sec=1.66 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:17,865] [   TRAIN]\u001b[0m - Epoch=5/6, Step=750/868 loss=0.1651 acc=0.9563 lr=0.000040 step/sec=1.65 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:24,007] [   TRAIN]\u001b[0m - Epoch=5/6, Step=760/868 loss=0.1846 acc=0.9313 lr=0.000040 step/sec=1.63 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:30,142] [   TRAIN]\u001b[0m - Epoch=5/6, Step=770/868 loss=0.1377 acc=0.9531 lr=0.000040 step/sec=1.63 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:36,281] [   TRAIN]\u001b[0m - Epoch=5/6, Step=780/868 loss=0.2056 acc=0.9375 lr=0.000040 step/sec=1.63 | ETA 00:54:01\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:42,421] [   TRAIN]\u001b[0m - Epoch=5/6, Step=790/868 loss=0.1257 acc=0.9594 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:48,568] [   TRAIN]\u001b[0m - Epoch=5/6, Step=800/868 loss=0.1668 acc=0.9500 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:40:54,699] [   TRAIN]\u001b[0m - Epoch=5/6, Step=810/868 loss=0.0983 acc=0.9688 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:00,822] [   TRAIN]\u001b[0m - Epoch=5/6, Step=820/868 loss=0.1491 acc=0.9469 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:07,285] [   TRAIN]\u001b[0m - Epoch=5/6, Step=830/868 loss=0.1493 acc=0.9563 lr=0.000040 step/sec=1.55 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:13,421] [   TRAIN]\u001b[0m - Epoch=5/6, Step=840/868 loss=0.1924 acc=0.9406 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:19,552] [   TRAIN]\u001b[0m - Epoch=5/6, Step=850/868 loss=0.1652 acc=0.9344 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:25,679] [   TRAIN]\u001b[0m - Epoch=5/6, Step=860/868 loss=0.1436 acc=0.9563 lr=0.000040 step/sec=1.63 | ETA 00:54:00\u001b[0m\n",
      "\u001b[34m[2022-05-10 16:41:43,982] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7615\u001b[0mm\n",
      "\u001b[32m[2022-05-10 16:41:43,983] [    INFO]\u001b[0m - Saving model checkpoint to ./ckpt\\epoch_5\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:51,756] [   TRAIN]\u001b[0m - Epoch=6/6, Step=10/868 loss=0.0830 acc=0.9750 lr=0.000040 step/sec=0.69 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:41:57,870] [   TRAIN]\u001b[0m - Epoch=6/6, Step=20/868 loss=0.0881 acc=0.9750 lr=0.000040 step/sec=1.64 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:03,983] [   TRAIN]\u001b[0m - Epoch=6/6, Step=30/868 loss=0.0700 acc=0.9750 lr=0.000040 step/sec=1.64 | ETA 00:54:18\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:10,105] [   TRAIN]\u001b[0m - Epoch=6/6, Step=40/868 loss=0.0654 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:16,226] [   TRAIN]\u001b[0m - Epoch=6/6, Step=50/868 loss=0.0742 acc=0.9719 lr=0.000040 step/sec=1.63 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:22,346] [   TRAIN]\u001b[0m - Epoch=6/6, Step=60/868 loss=0.0722 acc=0.9875 lr=0.000040 step/sec=1.63 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:28,464] [   TRAIN]\u001b[0m - Epoch=6/6, Step=70/868 loss=0.1017 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:34,586] [   TRAIN]\u001b[0m - Epoch=6/6, Step=80/868 loss=0.0556 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:40,700] [   TRAIN]\u001b[0m - Epoch=6/6, Step=90/868 loss=0.0433 acc=0.9906 lr=0.000040 step/sec=1.64 | ETA 00:54:17\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:46,822] [   TRAIN]\u001b[0m - Epoch=6/6, Step=100/868 loss=0.0736 acc=0.9844 lr=0.000040 step/sec=1.63 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:52,933] [   TRAIN]\u001b[0m - Epoch=6/6, Step=110/868 loss=0.0683 acc=0.9719 lr=0.000040 step/sec=1.64 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:42:59,047] [   TRAIN]\u001b[0m - Epoch=6/6, Step=120/868 loss=0.0477 acc=0.9875 lr=0.000040 step/sec=1.64 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:05,162] [   TRAIN]\u001b[0m - Epoch=6/6, Step=130/868 loss=0.0382 acc=0.9906 lr=0.000040 step/sec=1.64 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:11,278] [   TRAIN]\u001b[0m - Epoch=6/6, Step=140/868 loss=0.0894 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:17,396] [   TRAIN]\u001b[0m - Epoch=6/6, Step=150/868 loss=0.0567 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:23,514] [   TRAIN]\u001b[0m - Epoch=6/6, Step=160/868 loss=0.0859 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:16\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:29,633] [   TRAIN]\u001b[0m - Epoch=6/6, Step=170/868 loss=0.0599 acc=0.9875 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:35,754] [   TRAIN]\u001b[0m - Epoch=6/6, Step=180/868 loss=0.0496 acc=0.9844 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:41,878] [   TRAIN]\u001b[0m - Epoch=6/6, Step=190/868 loss=0.0665 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:48,000] [   TRAIN]\u001b[0m - Epoch=6/6, Step=200/868 loss=0.0764 acc=0.9844 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:43:54,117] [   TRAIN]\u001b[0m - Epoch=6/6, Step=210/868 loss=0.0926 acc=0.9719 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:00,238] [   TRAIN]\u001b[0m - Epoch=6/6, Step=220/868 loss=0.0742 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:15\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:06,364] [   TRAIN]\u001b[0m - Epoch=6/6, Step=230/868 loss=0.0583 acc=0.9812 lr=0.000040 step/sec=1.63 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:12,478] [   TRAIN]\u001b[0m - Epoch=6/6, Step=240/868 loss=0.0684 acc=0.9875 lr=0.000040 step/sec=1.64 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:18,598] [   TRAIN]\u001b[0m - Epoch=6/6, Step=250/868 loss=0.0797 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:24,713] [   TRAIN]\u001b[0m - Epoch=6/6, Step=260/868 loss=0.0706 acc=0.9750 lr=0.000040 step/sec=1.64 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:30,829] [   TRAIN]\u001b[0m - Epoch=6/6, Step=270/868 loss=0.0664 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:36,949] [   TRAIN]\u001b[0m - Epoch=6/6, Step=280/868 loss=0.1085 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:43,070] [   TRAIN]\u001b[0m - Epoch=6/6, Step=290/868 loss=0.1491 acc=0.9500 lr=0.000040 step/sec=1.63 | ETA 00:54:14\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:49,191] [   TRAIN]\u001b[0m - Epoch=6/6, Step=300/868 loss=0.0850 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:44:55,308] [   TRAIN]\u001b[0m - Epoch=6/6, Step=310/868 loss=0.0490 acc=0.9844 lr=0.000040 step/sec=1.63 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:01,423] [   TRAIN]\u001b[0m - Epoch=6/6, Step=320/868 loss=0.0821 acc=0.9688 lr=0.000040 step/sec=1.64 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:07,544] [   TRAIN]\u001b[0m - Epoch=6/6, Step=330/868 loss=0.0593 acc=0.9812 lr=0.000040 step/sec=1.63 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:13,657] [   TRAIN]\u001b[0m - Epoch=6/6, Step=340/868 loss=0.0799 acc=0.9719 lr=0.000040 step/sec=1.64 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:19,783] [   TRAIN]\u001b[0m - Epoch=6/6, Step=350/868 loss=0.1086 acc=0.9594 lr=0.000040 step/sec=1.63 | ETA 00:54:13\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2022-05-10 16:45:25,899] [   TRAIN]\u001b[0m - Epoch=6/6, Step=360/868 loss=0.0593 acc=0.9812 lr=0.000040 step/sec=1.64 | ETA 00:54:13\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:32,017] [   TRAIN]\u001b[0m - Epoch=6/6, Step=370/868 loss=0.0727 acc=0.9719 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:38,140] [   TRAIN]\u001b[0m - Epoch=6/6, Step=380/868 loss=0.1115 acc=0.9625 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:44,259] [   TRAIN]\u001b[0m - Epoch=6/6, Step=390/868 loss=0.1153 acc=0.9563 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:50,378] [   TRAIN]\u001b[0m - Epoch=6/6, Step=400/868 loss=0.0737 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:45:56,495] [   TRAIN]\u001b[0m - Epoch=6/6, Step=410/868 loss=0.1255 acc=0.9625 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:02,618] [   TRAIN]\u001b[0m - Epoch=6/6, Step=420/868 loss=0.0930 acc=0.9688 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:08,743] [   TRAIN]\u001b[0m - Epoch=6/6, Step=430/868 loss=0.1316 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:14,900] [   TRAIN]\u001b[0m - Epoch=6/6, Step=440/868 loss=0.1042 acc=0.9625 lr=0.000040 step/sec=1.62 | ETA 00:54:12\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:21,017] [   TRAIN]\u001b[0m - Epoch=6/6, Step=450/868 loss=0.0885 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:27,141] [   TRAIN]\u001b[0m - Epoch=6/6, Step=460/868 loss=0.0839 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:33,259] [   TRAIN]\u001b[0m - Epoch=6/6, Step=470/868 loss=0.1336 acc=0.9531 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:39,381] [   TRAIN]\u001b[0m - Epoch=6/6, Step=480/868 loss=0.1118 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:45,500] [   TRAIN]\u001b[0m - Epoch=6/6, Step=490/868 loss=0.0664 acc=0.9812 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:51,620] [   TRAIN]\u001b[0m - Epoch=6/6, Step=500/868 loss=0.0629 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:46:57,736] [   TRAIN]\u001b[0m - Epoch=6/6, Step=510/868 loss=0.0816 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:11\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:03,862] [   TRAIN]\u001b[0m - Epoch=6/6, Step=520/868 loss=0.1276 acc=0.9625 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:09,984] [   TRAIN]\u001b[0m - Epoch=6/6, Step=530/868 loss=0.0772 acc=0.9812 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:16,099] [   TRAIN]\u001b[0m - Epoch=6/6, Step=540/868 loss=0.0675 acc=0.9812 lr=0.000040 step/sec=1.64 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:22,219] [   TRAIN]\u001b[0m - Epoch=6/6, Step=550/868 loss=0.1215 acc=0.9719 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:28,336] [   TRAIN]\u001b[0m - Epoch=6/6, Step=560/868 loss=0.1317 acc=0.9469 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:34,453] [   TRAIN]\u001b[0m - Epoch=6/6, Step=570/868 loss=0.1296 acc=0.9594 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:40,571] [   TRAIN]\u001b[0m - Epoch=6/6, Step=580/868 loss=0.0922 acc=0.9563 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:46,690] [   TRAIN]\u001b[0m - Epoch=6/6, Step=590/868 loss=0.0825 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:10\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:52,807] [   TRAIN]\u001b[0m - Epoch=6/6, Step=600/868 loss=0.0705 acc=0.9781 lr=0.000040 step/sec=1.64 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:47:58,923] [   TRAIN]\u001b[0m - Epoch=6/6, Step=610/868 loss=0.1103 acc=0.9563 lr=0.000040 step/sec=1.63 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:05,048] [   TRAIN]\u001b[0m - Epoch=6/6, Step=620/868 loss=0.1033 acc=0.9719 lr=0.000040 step/sec=1.63 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:11,165] [   TRAIN]\u001b[0m - Epoch=6/6, Step=630/868 loss=0.0676 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:17,282] [   TRAIN]\u001b[0m - Epoch=6/6, Step=640/868 loss=0.0788 acc=0.9719 lr=0.000040 step/sec=1.63 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:23,398] [   TRAIN]\u001b[0m - Epoch=6/6, Step=650/868 loss=0.1212 acc=0.9656 lr=0.000040 step/sec=1.64 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:29,516] [   TRAIN]\u001b[0m - Epoch=6/6, Step=660/868 loss=0.0849 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:35,639] [   TRAIN]\u001b[0m - Epoch=6/6, Step=670/868 loss=0.1349 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:09\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:41,763] [   TRAIN]\u001b[0m - Epoch=6/6, Step=680/868 loss=0.0731 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:47,881] [   TRAIN]\u001b[0m - Epoch=6/6, Step=690/868 loss=0.0630 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:48:53,994] [   TRAIN]\u001b[0m - Epoch=6/6, Step=700/868 loss=0.1069 acc=0.9688 lr=0.000040 step/sec=1.64 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:00,114] [   TRAIN]\u001b[0m - Epoch=6/6, Step=710/868 loss=0.0830 acc=0.9812 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:06,231] [   TRAIN]\u001b[0m - Epoch=6/6, Step=720/868 loss=0.1204 acc=0.9625 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:12,349] [   TRAIN]\u001b[0m - Epoch=6/6, Step=730/868 loss=0.0688 acc=0.9781 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:18,468] [   TRAIN]\u001b[0m - Epoch=6/6, Step=740/868 loss=0.0736 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:24,589] [   TRAIN]\u001b[0m - Epoch=6/6, Step=750/868 loss=0.1098 acc=0.9625 lr=0.000040 step/sec=1.63 | ETA 00:54:08\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:30,710] [   TRAIN]\u001b[0m - Epoch=6/6, Step=760/868 loss=0.0769 acc=0.9750 lr=0.000040 step/sec=1.63 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:36,830] [   TRAIN]\u001b[0m - Epoch=6/6, Step=770/868 loss=0.1054 acc=0.9656 lr=0.000040 step/sec=1.63 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:43,139] [   TRAIN]\u001b[0m - Epoch=6/6, Step=780/868 loss=0.1022 acc=0.9688 lr=0.000040 step/sec=1.59 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:49,428] [   TRAIN]\u001b[0m - Epoch=6/6, Step=790/868 loss=0.1340 acc=0.9594 lr=0.000040 step/sec=1.59 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:49:55,437] [   TRAIN]\u001b[0m - Epoch=6/6, Step=800/868 loss=0.0870 acc=0.9781 lr=0.000040 step/sec=1.66 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:50:01,445] [   TRAIN]\u001b[0m - Epoch=6/6, Step=810/868 loss=0.1339 acc=0.9563 lr=0.000040 step/sec=1.66 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:50:07,444] [   TRAIN]\u001b[0m - Epoch=6/6, Step=820/868 loss=0.0907 acc=0.9781 lr=0.000040 step/sec=1.67 | ETA 00:54:07\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:50:13,442] [   TRAIN]\u001b[0m - Epoch=6/6, Step=830/868 loss=0.1139 acc=0.9719 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:50:19,444] [   TRAIN]\u001b[0m - Epoch=6/6, Step=840/868 loss=0.0999 acc=0.9656 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:50:25,444] [   TRAIN]\u001b[0m - Epoch=6/6, Step=850/868 loss=0.0816 acc=0.9688 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[36m[2022-05-10 16:50:31,445] [   TRAIN]\u001b[0m - Epoch=6/6, Step=860/868 loss=0.0714 acc=0.9844 lr=0.000040 step/sec=1.67 | ETA 00:54:06\u001b[0m\n",
      "\u001b[34m[2022-05-10 16:50:49,753] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7685\u001b[0mm\n",
      "\u001b[32m[2022-05-10 16:50:49,753] [    INFO]\u001b[0m - Saving model checkpoint to ./ckpt\\epoch_6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_dataset, epochs=6, batch_size=32, eval_dataset=valid_dataset, save_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75fc888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2022-05-10 16:51:26,142] [    EVAL]\u001b[0m - [Evaluation result] avg_acc=0.7490\u001b[0mm\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上评估当前训练模型\n",
    "result = trainer.evaluate(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "508abd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-05-10 16:51:26,190] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\ernie_tiny.pdparams\u001b[0m\n",
      "\u001b[32m[2022-05-10 16:51:29,198] [    INFO]\u001b[0m - Loaded parameters from C:\\Users\\23106\\Desktop\\weibopy\\ckpt\\best_model\\model.pdparams\u001b[0m\n",
      "\u001b[32m[2022-05-10 16:51:29,209] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-05-10 16:51:29,216] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\spm_cased_simp_sampled.model\u001b[0m\n",
      "\u001b[32m[2022-05-10 16:51:29,217] [    INFO]\u001b[0m - Already cached C:\\Users\\23106\\.paddlenlp\\models\\ernie-tiny\\dict.wordseg.pickle\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 你也不用说对不起,只是若相惜 \t Lable: 悲伤\n",
      "Data: 幸福其实很简单 \t Lable: 积极\n",
      "Data: 恐惧感啊。生病 \t Lable: 恐惧\n",
      "Data: 待你长发及腰,我们一起耕耘时光。我愿等待 \t Lable: 积极\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    # 悲伤\n",
    "    [\"你也不用说对不起,只是若相惜\"],\n",
    "    # 积极\n",
    "    [\"幸福其实很简单\"],\n",
    "    # 恐惧\n",
    "    [\"恐惧感啊。生病\"],\n",
    "    # 积极\n",
    "    [\"待你长发及腰,我们一起耕耘时光。我愿等待\"]\n",
    "]\n",
    "label_list=['愤怒', '积极', '悲伤', '无情绪', '恐惧', '惊奇']\n",
    "label_map = {\n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "model = hub.Module(\n",
    "    name='ernie_tiny',\n",
    "    task='seq-cls',\n",
    "    num_classes=6,\n",
    "    load_checkpoint='./ckpt/best_model/model.pdparams',\n",
    "    label_map=label_map)\n",
    "results = model.predict(data, max_seq_len=128, batch_size=32, use_gpu=True)\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text[0], results[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b15ac522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['强化班一直到考研结束吗']\n",
      "['老师我买了咱们的课可是视频强化班只有马原没有别的怎们办是没更新吗考研政治徐涛']\n",
      "['强化班有多少节一共多长时间能看完']\n",
      "['都了怎么评论区还是一群老熟人']\n",
      "['终于学生都要跑走了再不营业就剩我们这些老家伙了']\n",
      "['今年的核心考案又有一些小改动啊']\n",
      "['有人吗考研可以买这个来看了吗']\n",
      "['考研的涛涛子来啦政治不是梦']\n",
      "['核心考案又变好看了想收藏']\n",
      "['感谢涛哥考研政治分你强化课讲的偶然与必然让我记到了考场']\n",
      "['徐涛老师年请多指教']\n",
      "['四个小车车不知道上哪个了整的']\n",
      "['请问老师强化班怎么报名呀']\n",
      "['年的考研大纲是出来没有呢我有你年的核心考案需要更换吗']\n",
      "['看着换了封皮突然想收藏积累']\n",
      "['这个强化班是买核心考案就送吗还是']\n",
      "['今年出来卖的比往年时候要早一些～']\n",
      "['想知道这个微博的和站的课程内容有区别嘛为什么分两个软件售卖呀']\n",
      "['涛涛我想问一个问题你放的链接里的书都会送书签嘛']\n",
      "['传统艺能之出来卖了考研政治徐涛']\n",
      "['考研只要买全程班就可以了吗']\n",
      "['徐涛老师单单强化班有卖吗']\n",
      "['书买了视频在哪看']\n",
      "['走过路过不要错过啊徐涛老师又来卖喽']\n",
      "['俺来啦刚买好了我们上岸见']\n",
      "['为什么在淘宝看不到真题版本']\n",
      "['涛涛老师您是建议买全程班还是协议班呢']\n",
      "['又卖了涛涛老师']\n",
      "['只有全程班吗有无单独的强化班']\n",
      "['求一个艾宾浩斯遗忘曲线背诵表我给考研的男盆友要的看到可否给一个谢谢']\n",
      "['涛涛核心考案一月份真的会发货吗']\n",
      "['买了两个星期了我必是第一批发货']\n",
      "['原来开始的这么早']\n",
      "['徐老师我来了']\n",
      "['喜题集是做了会很高兴的题集嘛涛涛']\n",
      "['哥们我考两年了政治都是怎么解决']\n",
      "['强化班开课了嘛']\n",
      "['老师可以用年核心考案吗变化大吗']\n",
      "['有人拼吗']\n",
      "['上面的淘宝链接里政治全程包括强化课吗']\n",
      "['涛']\n",
      "['早就买好了坐等发货']\n",
      "['上涛涛的车啦']\n",
      "['明年这时候我也要成厉害的人许愿许愿']\n",
      "['什么时候有视频课呢涛涛']\n",
      "['感谢涛哥考研政治']\n",
      "['在哪里买强化班正版课']\n",
      "['该说不说的涛涛衣品蹭蹭上涨']\n",
      "['涛哥我上岸了政治感谢你每天的陪伴虽然你不知道哈哈']\n",
      "['徐涛老师现在是在研途吗还是只和他们有合作啊']\n",
      "['核心考案视频讲解在哪有']\n",
      "['陕西全境停发这是什么鬼']\n",
      "['走过路过不要错过涛涛保我上岸']\n",
      "['']\n",
      "['老师多多指教']\n",
      "['核心考案的课在哪儿看呀']\n",
      "['涛涛今年几月份开始上课呀']\n",
      "['我又要买书了']\n",
      "['哈']\n",
      "['买了全程班是不是就不用单买书了呀']\n",
      "['买了全程课还需要买另外的教材吗']\n",
      "['我准备好了']\n",
      "['我恍惚了希望不要买的书']\n",
      "['来啦时隔三年我又来啦不变的选择']\n",
      "['现在买题库早吗主要是强化班还没出现在买了有点怕吃灰']\n",
      "['热卖中']\n",
      "['我要就着涛涛的强化课下饭']\n",
      "['涛涛我继续跟你了心气儿太高北外考劈叉了继续冲鸭']\n",
      "['哭了']\n",
      "['或者背诵笔记可以用强化课吗我真的不想再买第三本核心考案了']\n",
      "['我拟录取啦谢谢涛涛子政治竟然之后还要看你的课提高我的政治觉悟']\n",
      "['政治认准涛哥感谢涛涛届已上岸加油届']\n",
      "['强化课在哪里看啊']\n",
      "['算全年最低价么']\n",
      "['徐涛老师二战要买核心考案吗']\n",
      "['火速出一个政治英语协议超便宜']\n",
      "['老师两个孩子妈妈工作多年的演员同学报道考研看您的课表情可太可爱了哈哈完全能听懂讲得真好']\n",
      "['铁粉']\n",
      "['']\n",
      "['徐涛老师您结婚啦真好奇']\n",
      "['']\n",
      "['书课包在哪看呀']\n",
      "['核心考案的那本书有配套视频讲解吗']\n",
      "['强化班有吗']\n",
      "['有和我一起买站上的精讲班吗站上我们一起你只要付']\n",
      "['我再来听一次强化班']\n",
      "['有要课的嘛准备出']\n",
      "['去年买过书了还需要买吗']\n",
      "['今年政治变化如何']\n",
      "['买核心考案会赠强化班的课吗']\n",
      "['想问一下强化班可以单买吗']\n",
      "['默默问一下核心考案和强化班课程对应嘛']\n",
      "['有没有哪位学姐学长传授孩子一下笔记怎么做是全部写下来还是记书上还是重点记']\n",
      "['新疆不发货']\n",
      "['那个的核心考案还能用吗现在物流不给力想问问']\n",
      "['网课是在哪买']\n",
      "['快递不往这儿发拿不到书天天在家干着急难受的一']\n",
      "['为什么课程不是讲的版新书的内容啊']\n",
      "['老师思修不是已经改成思法了吗为什么核心考案里还是思修啊考研政治徐涛']\n",
      "['我上岸了徐涛老师']\n",
      "['历史的面孔主要讲啥']\n",
      "['']\n",
      "['不明白为什么说联系具有条件性联系不是客观存在的嘛一个联系没有条件就不存在嘛']\n",
      "['涛涛我来看你啦']\n",
      "['有点想二战了']\n",
      "['每次看到版涛都想抱走']\n",
      "['老师我买你的书我看了很多家价格都不一样但店铺都是云图的拼多多的和淘宝价格不一样淘宝的两家同样标签的店铺价格不一样而且还有评论说书的价格浮动很大我真不知道该咋办了']\n",
      "['哈哈哈']\n",
      "['涛涛老师我考研败了但是政治成绩我很满意年再来一回涛涛开课了吗最近在忙着毕业论文']\n",
      "['老师全程班多久能学完政治应该从什么时候开始']\n",
      "['的书还没拆今年能用吗']\n",
      "['有出的吗想买']\n",
      "['涛哥关注你了']\n",
      "['辽宁快递停发买不到优题库好着急']\n",
      "['涛涛老师具体在上海杨浦区什么位置疫情结束想去看看']\n",
      "['徐涛老师您好我是甘肃省的一位考生复试笔试环节由于疫情原因拍照上传钉钉的我的大多数同学都是未读老师就把分数给出来了我们笔试都没过笔试占遇到这种不公平现象想请徐涛老师为我们发声']\n",
      "['老师全程班是包括了基础班强化班刷题班冲刺班时政班还有押题班了吗']\n",
      "['老师喜题集送的课是刷题班吗我是站上买的课程只有基础班和强化班到时候还要另外买刷题班吗']\n",
      "['有人出未激活的全程班么']\n",
      "['电脑上可以上吗']\n",
      "['怎么看课在哪买书有没有人救救我']\n",
      "['老师今年要开大那去年课程里面讲的关于大的一系列内容课程听了还有用吗']\n",
      "['强化班什么时候出啊']\n",
      "['老师优题库在哪里买呢']\n",
      "['可爱的涛老师我又来了今年跟您希望上岸']\n",
      "['报全程班就可以了吗没有政治基础']\n",
      "['文登考研寄宿吃住学一体性价比超高坐标武汉']\n",
      "['有组团买课的吗有优惠']\n",
      "['请问怎么直接单纯购买强化班']\n",
      "['有没有拼课的研友']\n",
      "['考研应该啥时候学政治啊好迷茫']\n",
      "['核心考案的配套视频在哪里看']\n",
      "['真的不敢考研了']\n",
      "['老师是不是买书就附赠强化课的视频不需要自己再买了']\n",
      "['纠结全称班个协议班有人报了吗可以给点意见吗']\n",
      "['考研怎么选啊']\n",
      "['我是一个考研小白考研应该买哪个啊有人支支招嘛谢谢谢谢']\n",
      "['想问一下考研应该什么时候学政治']\n",
      "['强化班开始更新了嘛']\n",
      "['一年一年又一年飞逝就在一转眼唯一永远不改变']\n",
      "['请问有无课程安排表呀那种精确到日期的']\n",
      "['哭了疫情发不了货']\n",
      "['徐涛老师的基础课更新了没找的资源都是说沿用去年的']\n",
      "['涛啊站看你看到你的双下巴了你又胖了']\n",
      "['毛中特改的多']\n",
      "['新疆为什么不发货']\n",
      "['想有个研友（女）']\n",
      "['新疆不发货呀表示好难过']\n",
      "['徐涛老师的政治强化课在哪听呀有谁知道吗']\n",
      "['优题库什么时候发出来呀']\n",
      "['老师您的课是在哪个平台啊']\n",
      "['马理论考研只听老师的课加上背书可以吗']\n",
      "['徐涛老师请多指教']\n",
      "['涛今天国家线能出吗']\n",
      "['有好兄弟知道是先刷题还是先学核心考案啊为啥刷题课出来了核心考案没有']\n",
      "['为什么年的核心考案不是根据最新版的考研政治编写的少了好多内容']\n",
      "['实在调剂不了就准备三战明年高低考个先来占个位']\n",
      "['弱弱问一句单独买书和全程班区别大嘛想省点钱']\n",
      "['唐婶节日快乐']\n",
      "['这个全程班从月份开始有没有可以从七月份开始的课']\n",
      "['核心考案里面有视频课嘛']\n",
      "['必须选徐涛好吗真的非常喜欢涛涛很放松很能学到知识今年政治谢涛']\n",
      "['年考研政治强化班什么时候开始更新呢']\n",
      "['上车了等待发车']\n",
      "['想买全部小黄书赶快上链接哈哈哈哈哈']\n",
      "['新东方里的徐涛和这个有啥区别考研政治徐涛']\n",
      "['我是准备考研的小白求问评论区各位前辈政治和专业课都什么时候开始呢～']\n",
      "['请问核心考案配了视频吗']\n",
      "['请问徐涛老师年强化课是录播课吗']\n",
      "['只想听强化课还有吗']\n",
      "['的核心考案已经上线了啊']\n",
      "['姐妹们我想问一下徐涛老师在新东方是主讲吗']\n",
      "['二战生请教一个问题去年徐涛的强化班除了思修全都看了并且做了很详细的笔记那么今年应该怎么看呢马原和史纲应该不用再看了吧这两个每年基本都一样的我只需要把思修和新的毛中特一看就可以了吧我不太想重新再看一遍因为时间真的有限去年时间不够的那种恐惧和痛苦真的刻骨铭心']\n",
      "['能给准备二战的人一点安慰吗']\n",
      "['有没有人和我觉得一样感觉核心考案马原编的特别绕零散']\n",
      "['考研互助群有人一起吗']\n",
      "['']\n",
      "['所以强化班能单买不']\n",
      "['之前和书籍的框架对不上笔记不顺畅好难过']\n",
      "['徐涛老师有没有政治备考计划啊']\n",
      "['全程班也会有这个核心考案的课吗']\n",
      "['考研来了']\n",
      "['涛我历史的面孔都看完这么久了还不出新出吗']\n",
      "['老师是买书就送强化班的课程吗']\n",
      "['我以为刚才魔术站起来的观众是你激动了好一会']\n",
      "['中奖忘记填地址了怎么办']\n",
      "['请问涛涛今年还会更每月时政热点吗']\n",
      "['强化班啥时候更新吖']\n",
      "['涛涛老师好']\n",
      "['涛涛老师请教一个问题：根据唯物史观对人的定义如果现实中存在这样一个人他是由动物抚养长大的但是具有人的外在样貌属性然后不小心被我打死了法律判我死刑我可以打官司吗毕竟法律体现的是国家意识而唯物史观是国家理论武器的一部分矛与盾谁厉害']\n",
      "['好难过心情不好看看涛涛老师的微博感觉没啥大不了的']\n",
      "['喜题集']\n",
      "['来了涛哥']\n",
      "['想问一下考研的课是已经开始了吗']\n",
      "['']\n",
      "['小白想请教一下应该买什么书']\n",
      "['上岸列车发车咯']\n",
      "['老师报了您的全程班但是看到只有协议班才有最后的押题课程意味着全程班没有对吗']\n",
      "['有单独的强化班吗']\n",
      "['强化班哪里听啊家人们']\n",
      "['第一次看涛涛的课是年']\n",
      "['涛涛老师明年我不要跟你了']\n",
      "['老公']\n",
      "['徐涛老师二十大的召开会再次影响到毛中特知识的变化吗']\n",
      "['啥时候出版啊老师']\n",
      "['我又来了']\n",
      "['老粉来给涛涛打个座機买不了吃亏买不了上当']\n",
      "['买了全程班就不用再单独买全套书了是嘛']\n",
      "['必须全套入等疫情完了快递恢复了就立马下单']\n",
      "['']\n",
      "['不懂就问啊这个书里面带视频吗']\n",
      "['我又可以出来卖了']\n",
      "['号就买了坐等发货']\n",
      "['爸爸']\n",
      "['落榜生来看看']\n",
      "['封面又变可爱了想收藏']\n",
      "['老徐终于开始营业了']\n",
      "['时间真快啊转眼就考研了']\n",
      "['真的来了']\n",
      "['我又来了']\n",
      "['跟着涛涛走准没错']\n",
      "['哇哦虎年限定核心考案真想快快入手']\n",
      "['马上迎来一批新粉丝']\n",
      "['明白了这就开始背考前题']\n",
      "['涛涛我同性恋了']\n",
      "['的需要买吗']\n",
      "['买那个啊玉兔玉兔']\n",
      "['考了我想我会考上西北政法大学的对吧']\n",
      "['劳模没跑了考研政治徐涛']\n",
      "['居然都开始考研了']\n",
      "['']\n",
      "['报了课结果课程码也没有卡号也不知道是什么客服发的链接还是过期的']\n",
      "['徐涛老师谢谢您我政治选择题做的很好全靠刷您的预测卷']\n",
      "['您已成功发布电商博文快来领取专属流量福利吧注意：流量资源奖励不可累加到期后将自动从您的资源包清除喽抓紧机会吧戳链接领取：网页链接']\n",
      "['考研的想问问用年的资料会有影响吗']\n",
      "['救命啊真的有必要吗我穷好贵啊有没有拼的啊']\n",
      "['涛哥你的课真是我考研生活中唯一的快乐源泉啊太爱你了']\n",
      "['我想知道哪里找啊就基础串讲的']\n",
      "['呜呜呜更新顺序是马原思修后面就会更毛中特嘛']\n",
      "['强化在哪买啊']\n",
      "['一战跟涛涛子没怎么费工夫就旱区二战我又来了']\n",
      "['涛哥去年没钱听您的盗版课进了复试但是还是落榜了今年我还没钱但是我还要听您的盗版课等有能力了我会回报社会的一看到您我就有坚持下去的信心和希望']\n",
      "['感觉还不错买了买了']\n",
      "['有人要出涛涛的课嘛']\n",
      "['我想问一下报了全程班需要买书吗']\n",
      "['微博是不是不可以买书只能跳到淘宝去这个']\n",
      "['内卷太严重了我感觉我自己学上不了岸呀各位有好的推荐吗']\n",
      "['先看去年强化的可以吗早卷早超生考研狗见了都摇头']\n",
      "['']\n",
      "['']\n",
      "['年的课什么时候开呢']\n",
      "['请问强化班什么时候出呀']\n",
      "['新人书有了课呢']\n",
      "['政治谢谢徐涛老师']\n",
      "['']\n",
      "['感谢徐涛老师上了']\n",
      "['听涛哥的强化班一遍政治分很满意了']\n",
      "['考研转考公出徐老师课程']\n",
      "['是特定时间一起上课的意思吗']\n",
      "['徐涛老师为历史的面孔打杨步伟女士那篇您的见解让我受益匪浅（知行能否合一暂且不论）希望徐涛老师继续输出']\n",
      "['买了核心考案课程在哪里领取呀']\n",
      "['有没有人收到考研违规通知啊']\n",
      "['大家有没有一起拼课的阿']\n",
      "['强化班能单买吗']\n",
      "['这个链接比在研途直接买课便宜了点这链接是正规的吗']\n",
      "['这个全程班课有必要买吗']\n",
      "['准备考研哪个平台可以购买徐涛老师的全程班我看站只有基础和强化']\n",
      "['有单独的强化班吗']\n",
      "['可以只买强化班吗']\n",
      "['涛涛刚看完历史的面孔有没有其他书籍可以推荐嘞']\n",
      "['跟相比更新内容多吗']\n",
      "['我可以去别家买徐涛老师的课吗我点进链接去怎么发现研途这家评论不太好啊也不是很懂问问可以吗']\n",
      "['强化班几月出啊现在就只有基础班么']\n",
      "['你的强化课在哪买']\n",
      "['我是的书还用买的书吗']\n",
      "['核心考案啥时候开课']\n",
      "['强化班更新快点啊我等不及了']\n",
      "['在职怎么准备考研呀']\n",
      "['核心考案课程开始了吗']\n",
      "['有人需要徐涛老师的政治课吗我放弃考研了今年月刚买的课还没开始看块转卖']\n",
      "['核心考案中第页马克思主义的鲜明特征部分我想问一下在新版书籍中有没有革命性这一点']\n",
      "['考研已上岸政治特来感谢徐涛老师的核心考案尤其是马哲讲的太好了']\n",
      "['唉去年今年加油吧懇求']\n",
      "['徐涛老师的强化班几月更新完呀']\n",
      "['考研政治还得是涛涛啊噶油']\n",
      "['本来跟一个老朋友闹的很不愉快但不愉快之前他给我推荐了涛涛虽然后来不愉快不联系了但我依然感谢他让我认识了涛涛']\n",
      "['跟着学了一年考了三十分感觉人生到达了巅峰']\n",
      "['核心考案的视频讲解哪里有']\n",
      "['问一下大家买书会送配套视频吗']\n",
      "['你可以永远相信徐涛来自政治选择分选手']\n",
      "['外应有没有小伙伴组队练复试呀']\n",
      "['不会写研复简历的私信我']\n",
      "['现在开始刷题吗']\n",
      "['想问一下全程班多少钱啊']\n",
      "['课啥时候开']\n",
      "['哈哈']\n",
      "['最幸福的小狐狸这就是徐涛老师～涛涛很有趣诶可以关注一下']\n",
      "['出全程班个人原因不考了手机号可以改成自己的']\n",
      "['老师这个链接在淘宝买吗但大家反馈后台不怎么完善呀']\n",
      "['徐涛老师去年买过书的今年还用买吗考研政治徐涛']\n",
      "['想问问买了核心考案是不是还要买那个课后题啊课后题是跟核心考案的章节相对应嘛就是看了一个章节然后就做题是这样的意思嘛']\n",
      "['开始上强化班了刚上完哲学的基本问题接着在专业课上又学到Материяпервичнасозданиевторично（物质是第一性意识是第二性）一些奇奇怪怪的交叉学科输入']\n",
      "['徐涛老师的强化班在哪儿看呀']\n",
      "['耳东陈红']\n",
      "['把烟掐了你给我报个']\n",
      "['暖暖的小南风是玉儿吖']\n",
      "['什么时候有核心考案的讲解啊']\n",
      "['全程班跟协议班报哪一个呀好纠结']\n",
      "['讲的很好就是听不太懂']\n",
      "['有时候听不明白啊']\n",
      "['小白问一下核心考案需要背吗']\n",
      "['袁版的核心考案']\n",
      "['可爱的大人']\n",
      "['课']\n",
      "['出考研政治徐涛全程班（因为不准备考研了所以想快快便宜出掉有需要的滴滴我）（课都还没开始看书也是新的没拆封到时候可寄出）祝大家考研一切顺利呀']\n",
      "['有想来考研寄宿的嘛可以来太极考研哦宿舍设施齐全']\n",
      "['考研想请问一下不是还有二十大吗核心教案这么早就出了呀现在买可以吗']\n",
      "['']\n",
      "['生物师范生考研选择学科教学会被卷死不学硕专硕哪个好上岸']\n",
      "['出全程班金钱（因为不准备考研了所以想快快便宜出掉有需要的滴滴我）（课都还没开始看书也是新的没拆封到时候可寄出）祝大家考研一切顺利呀']\n",
      "['虽然没上岸但是还是感谢涛哥让我一政治小白整了今年我加油一定上岸']\n",
      "['成绩不理想的同学抓紧转到留学了可半工半读一年到一年半毕业']\n",
      "['包公亭子']\n",
      "['橦不橦啊']\n",
      "['']\n",
      "['什么时候开始上课呢']\n",
      "['嘉兴']\n",
      "['大家听课的方式都被老师看的透透的连封面画的都是倍速']\n",
      "['的课最早的什么时候开始啊']\n",
      "['怎样能只购买强化课程呢']\n",
      "['我想请问下我今年准备考研我听我考过的朋友说大纲是月份出的现在要买核心考案吗']\n",
      "['视频课什么时候开始呀']\n",
      "['']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39796/3664872123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetchUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[0mcomments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparseJson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0msave_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39796/3664872123.py\u001b[0m in \u001b[0;36mfetchUrl\u001b[1;34m(pid, uid, max_id)\u001b[0m\n\u001b[0;32m     24\u001b[0m     }\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "def fetchUrl(pid, uid, max_id):\n",
    "    # url\n",
    "    url = \"https://weibo.com/ajax/statuses/buildComments\"\n",
    "    # 请求头\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\",\n",
    "    }\n",
    "    # 参数\n",
    "    params = {\n",
    "        \"flow\": 0,\n",
    "        \"is_reload\": 1,\n",
    "        \"id\": pid,\n",
    "        \"is_show_bulletin\": 3,\n",
    "        \"is_mix\": 0,\n",
    "        \"max_id\": max_id,\n",
    "        \"count\": 20,\n",
    "        \"uid\": uid,\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, headers=headers, params=params)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def parseJson(jsonObj):\n",
    "\n",
    "    data = jsonObj[\"data\"]\n",
    "    max_id = jsonObj[\"max_id\"]\n",
    "    commentData = []\n",
    "    for item in data:\n",
    "        # 评论id\n",
    "        comment_Id = item[\"id\"]\n",
    "        # 评论内容\n",
    "        content = BeautifulSoup(item[\"text\"], \"html.parser\").text\n",
    "        # 评论时间\n",
    "        created_at = item[\"created_at\"]\n",
    "        # 点赞数\n",
    "        like_counts = item[\"like_counts\"]\n",
    "        # 评论数\n",
    "        total_number = item[\"total_number\"]\n",
    "\n",
    "        # 评论者 id，name，city\n",
    "        user = item[\"user\"]\n",
    "        userID = user[\"id\"]\n",
    "        userName = user[\"name\"]\n",
    "        userCity = user[\"location\"]\n",
    "        content=re.sub('[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~\\s]+', \"\", content)\n",
    "        emoji = json.load(open('C:/Users/23106/Desktop/weibopy/emoji.json', 'r', encoding='utf8'))\n",
    "        for emoji, emoji_text in emoji.items():\n",
    "            content = content.replace(emoji,emoji_text )\n",
    "        dataItem = [content]\n",
    "        print(dataItem)\n",
    "        commentData.append(dataItem)\n",
    "\n",
    "    return commentData, max_id\n",
    "def save_data(data, path, filename):\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    dataframe.to_csv(path + filename, mode='a', index=False, sep=',', header=False )\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    pid = 4727457598933626      # 微博id，固定\n",
    "    uid = 2140522467            # 用户id，固定\n",
    "    max_id = 0\n",
    "    path = \"C:/Users/23106/Desktop/weibopy/new/\"           # 保存的路径\n",
    "    filename = \"comments.csv\"   # 保存的文件名\n",
    "    \n",
    "    #csvHeader = [[\"评论id\", \"发布时间\", \"用户id\", \"用户昵称\", \"用户城市\", \"点赞数\", \"回复数\", \"评论内容\"]]\n",
    "    #save_data(csvHeader, path, filename)\n",
    "\n",
    "    while(True):\n",
    "        html = fetchUrl(pid, uid, max_id)\n",
    "        comments, max_id = parseJson(html)\n",
    "        save_data(comments, path, filename)\n",
    "        # max_id 为 0 时，表示爬取结束\n",
    "        if max_id == 0:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23088f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
